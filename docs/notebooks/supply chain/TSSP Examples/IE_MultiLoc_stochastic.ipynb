{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.00] Initializing mpi-sppy\n"
     ]
    }
   ],
   "source": [
    "from pyomo.environ import *\n",
    "import mpisppy.utils.sputils as sputils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import sys\n",
    "sys.path.append('../../../../src')\n",
    "import pandas\n",
    "import random\n",
    "import math\n",
    "from itertools import product\n",
    "from energiapy.components.temporal_scale import TemporalScale\n",
    "from energiapy.components.resource import Resource, VaryingResource\n",
    "from energiapy.components.process import Process, ProcessMode, VaryingProcess\n",
    "from energiapy.components.location import Location\n",
    "from energiapy.components.transport import Transport\n",
    "from energiapy.components.network import Network\n",
    "from energiapy.components.scenario import Scenario\n",
    "# from energiapy.model.constraints.demand import constraint_demand2\n",
    "from energiapy.components.result import Result\n",
    "from energiapy.model.formulate import formulate, Constraints, Objective\n",
    "from energiapy.plot import plot_results, plot_scenario, plot_location\n",
    "from energiapy.model.solve import solve\n",
    "from pyomo.environ import Param\n",
    "from energiapy.utils.scale_utils import scale_pyomo_set\n",
    "from energiapy.utils.scale_utils import scale_list, scale_tuple\n",
    "from energiapy.model.constraints.constraints import make_constraint, Cons\n",
    "from energiapy.model.formulate import constraint_export"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.286330Z",
     "start_time": "2024-09-18T14:27:15.594674Z"
    }
   },
   "id": "77cd58c13662186a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_time_intervals = 7  # Number of time intervals in a planning horizon    (L_chi)\n",
    "_coms = 1\n",
    "_exec_scenarios = 52  # Number of execution scenarios                     (chi)\n",
    "\n",
    "M = 1e3  # Big M"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.301892Z",
     "start_time": "2024-09-18T14:27:16.287460Z"
    }
   },
   "id": "2face643bc99c79a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def create_list(n_t:int, n:int):\n",
    "    return [1]*n + [0]*(n_t - n)\n",
    "\n",
    "def create_event_dict(n_total:int):\n",
    "    default_list = [1]*n_total\n",
    "    event_dict = {\n",
    "    # 'cap1_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap1_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap1_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap1_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_process'): create_list(52)})},\n",
    "             \n",
    "    'cap2_13': {'prob': 0.05, 'factor': pandas.DataFrame(data={('loc2','com1_process'): create_list(n_total, 13)})},\n",
    "    'cap2_26': {'prob': 0.1, 'factor': pandas.DataFrame(data={('loc2', 'com1_process'): create_list(n_total, 26)})},\n",
    "    'cap2_39': {'prob': 0.15, 'factor': pandas.DataFrame(data={('loc2', 'com1_process'): create_list(n_total, 39)})},\n",
    "    'cap2_52': {'prob': 0.7, 'factor': pandas.DataFrame(data={('loc2', 'com1_process'): default_list})},\n",
    "     \n",
    "    # 'cap3_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc3','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap3_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc3', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap3_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc3', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap3_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc3', 'com1_process'): create_list(52)})},\n",
    "    #  \n",
    "    # 'cap4_13': {'prob': 0.01, 'factor': pandas.DataFrame(data={('loc4','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap4_26': {'prob': 0.05, 'factor': pandas.DataFrame(data={('loc4', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap4_39': {'prob': 0.1, 'factor': pandas.DataFrame(data={('loc4', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap4_52': {'prob': 0.84, 'factor': pandas.DataFrame(data={('loc4', 'com1_process'): default_list})},\n",
    "    #  \n",
    "    # 'cap5_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc5','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap5_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc5', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap5_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc5', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap5_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc5', 'com1_process'): create_list(52)})},\n",
    "    #  \n",
    "    # 'cap6_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap6_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap6_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap6_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_process'): create_list(52)})},\n",
    "    #  \n",
    "    # 'cap7_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc7','com1_process'): create_list(n_total, 13)})},\n",
    "    # 'cap7_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc7', 'com1_process'): create_list(n_total, 26)})},\n",
    "    # 'cap7_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc7', 'com1_process'): create_list(n_total, 39)})},\n",
    "    # 'cap7_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc7', 'com1_process'): create_list(52)})},\n",
    "    #  \n",
    "    # 'res1_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1','com1_pur'): create_list(n_total, 13)})},\n",
    "    # 'res1_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_pur'): create_list(n_total, 26)})},\n",
    "    # 'res1_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_pur'): create_list(n_total, 39)})},\n",
    "    # 'res1_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc1', 'com1_pur'): create_list(52)})},\n",
    "    #  \n",
    "    # 'res6_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6','com1_pur'): create_list(n_total, 13)})},\n",
    "    # 'res6_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_pur'): create_list(n_total, 26)})},\n",
    "    # 'res6_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_pur'): create_list(n_total, 39)})},\n",
    "    # 'res6_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={('loc6', 'com1_pur'): create_list(52)})},\n",
    "    #  \n",
    "    # 'trans14_13': {'prob': 0.25, 'factor': pandas.DataFrame(data={'trans14': create_list(n_total, 13)})},\n",
    "    # 'trans14_26': {'prob': 0.25, 'factor': pandas.DataFrame(data={'trans14': create_list(n_total, 26)})},\n",
    "    # 'trans14_39': {'prob': 0.25, 'factor': pandas.DataFrame(data={'trans14': create_list(n_total, 39)})},\n",
    "    # 'trans14_52': {'prob': 0.25, 'factor': pandas.DataFrame(data={'trans14': create_list(52)})},\n",
    "    }\n",
    "    \n",
    "    return event_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.317389Z",
     "start_time": "2024-09-18T14:27:16.302930Z"
    }
   },
   "id": "5dda378f7d7b2633",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "event_dict = create_event_dict(n_total=_exec_scenarios)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.333389Z",
     "start_time": "2024-09-18T14:27:16.318398Z"
    }
   },
   "id": "607f80c011c3e696",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to generate the scenario dictionary for n sets of events\n",
    "def create_scenario_dict(event_dict):\n",
    "    # Extract unique event prefixes (e.g., 'cap2', 'cap4', ...)\n",
    "    event_prefixes = set(key.split('_')[0] for key in event_dict)\n",
    "\n",
    "    # Group events by their prefixes\n",
    "    grouped_events = {prefix: [key for key in event_dict if key.startswith(prefix)] for prefix in event_prefixes}\n",
    "\n",
    "    # Create all possible combinations of events across the different groups\n",
    "    event_combinations = list(product(*grouped_events.values()))\n",
    "\n",
    "    scenario_dict = {}\n",
    "\n",
    "    # Iterate over all event combinations\n",
    "    for combination in event_combinations:\n",
    "        # Construct the scenario key\n",
    "        scenario_key = '_'.join(combination)\n",
    "\n",
    "        # Calculate the probability of this scenario\n",
    "        prob = 1\n",
    "        combined_factor = None\n",
    "\n",
    "        for event_key in combination:\n",
    "            # Multiply probabilities\n",
    "            prob *= event_dict[event_key]['prob']\n",
    "\n",
    "            # Combine factors (assumes they are pandas DataFrames)\n",
    "            if combined_factor is None:\n",
    "                combined_factor = event_dict[event_key]['factor'].copy()\n",
    "            else:\n",
    "                combined_factor = combined_factor.add(event_dict[event_key]['factor'], fill_value=0)\n",
    "\n",
    "        # Add to the scenario dictionary\n",
    "        scenario_dict[scenario_key] = {'prob': prob, 'factor': combined_factor}\n",
    "\n",
    "    return scenario_dict\n",
    "\n",
    "# Example usage\n",
    "scenario_dict = create_scenario_dict(event_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.349994Z",
     "start_time": "2024-09-18T14:27:16.335464Z"
    }
   },
   "id": "63a5ff0501d8411f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scenario_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.365446Z",
     "start_time": "2024-09-18T14:27:16.351004Z"
    }
   },
   "id": "4c9dc844f19bfdc1",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# len(scenario_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.381035Z",
     "start_time": "2024-09-18T14:27:16.366496Z"
    }
   },
   "id": "e4fcfa6db5bb575e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sum(scenario_dict[scen]['prob'] for scen in scenario_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.396385Z",
     "start_time": "2024-09-18T14:27:16.382109Z"
    }
   },
   "id": "42893e3c754ea8e5",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# total_prob = sum(scenario_dictionary[name]['prob'] for name in scenario_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.411826Z",
     "start_time": "2024-09-18T14:27:16.397448Z"
    }
   },
   "id": "6b5cd0b9455f09c5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for name in scenario_names:\n",
    "#     scenario_dictionary[name]['prob'] = scenario_dictionary[name]['prob']/total_prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.427885Z",
     "start_time": "2024-09-18T14:27:16.412835Z"
    }
   },
   "id": "2dea3e25deb33782",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scenario_names = list(scenario_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.444024Z",
     "start_time": "2024-09-18T14:27:16.429024Z"
    }
   },
   "id": "5b0b4e2ad8f5c657",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scenario_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.459368Z",
     "start_time": "2024-09-18T14:27:16.445033Z"
    }
   },
   "id": "7f55317eae9ee425",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# type(scenario_dict['cap4_13_cap2_26']['factor'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.474869Z",
     "start_time": "2024-09-18T14:27:16.460407Z"
    }
   },
   "id": "27462056789ea8d6",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_model(scen_df=pandas.DataFrame()):\n",
    "    \n",
    "    default_df = pandas.DataFrame(data=[1]*_exec_scenarios)\n",
    "    \n",
    "    # Define temporal scales\n",
    "    scales = TemporalScale(discretization_list=[1, _exec_scenarios, _time_intervals])\n",
    "    \n",
    "    # ======================================================================================================================\n",
    "    # Declare resources/commodities\n",
    "    # ======================================================================================================================\n",
    "    com1_pur = Resource(name='com1_pur', cons_max=M, block={'imp': 1, 'urg': 1}, price=0.00, label='Commodity 1 consumed from outside the system', varying=[VaryingResource.DETERMINISTIC_AVAILABILITY])\n",
    "    \n",
    "    com1_in = Resource(name='com1_in', label='Commodity 1 received')\n",
    "    com1_out = Resource(name='com1_out', label='Commodity 1 to be sent out')\n",
    "    \n",
    "    com1_loc1_out = Resource(name='com1_loc1_out', label='Commodity 1 sent out from location 1')\n",
    "    com1_loc2_out = Resource(name='com1_loc2_out', label='Commodity 1 sent out from location 2')\n",
    "    com1_loc3_out = Resource(name='com1_loc3_out', label='Commodity 1 sent out from location 3')\n",
    "    com1_loc4_out = Resource(name='com1_loc4_out', label='Commodity 1 sent out from location 4')\n",
    "    com1_loc5_out = Resource(name='com1_loc5_out', label='Commodity 1 sent out from location 5')\n",
    "    com1_loc6_out = Resource(name='com1_loc6_out', label='Commodity 1 sent out from location 6')\n",
    "    com1_loc7_out = Resource(name='com1_loc7_out', label='Commodity 1 sent out from location 7')\n",
    "    \n",
    "    com1_sold = Resource(name='com1_sold', revenue=0.00, demand=True, sell=True, label='Commodity 1 sold to outside the system')\n",
    "    \n",
    "    \n",
    "    # ======================================================================================================================\n",
    "    # Declare processes/storage capacities\n",
    "    # ======================================================================================================================\n",
    "    com1_process_capacity = 500\n",
    "    \n",
    "    # prod_max = {0: 0.25*com1_process_capacity, 1: 0.5*com1_process_capacity, 2: 0.75*com1_process_capacity, 3: 0.95*com1_process_capacity, 4: com1_process_capacity}\n",
    "    # prod_min = {0: 0, 1: 0.25*com1_process_capacity, 2: 0.5*com1_process_capacity, 3: 0.75*com1_process_capacity, 4: 0.95*com1_process_capacity}\n",
    "    # rate_max = {0:1.25/2, 1: 1/2, 2: 0.75/2, 3: 0.5/2, 4: 0.25/2}\n",
    "    # mode_ramp = {(0,1): 5, (1,2): 5}\n",
    "    \n",
    "    com1_procure = Process(name='procure com1', prod_max=com1_process_capacity, conversion={com1_pur: -1, com1_in: 1}, capex=25, vopex=0.01, prod_min=0.01, label='Procure com1')\n",
    "    com1_sell = Process(name='sell com1', prod_max=com1_process_capacity, conversion={com1_out: -1, com1_sold: 1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Sell com1')\n",
    "    # com1_opt_procure = Process(name='procure optional com1', prod_max=75, conversion={com1_pur: -1, com1_in:1}, capex=10, vopex=0.1, prod_min=0.01, label='Procure optional com1')\n",
    "    \n",
    "    com1_receive_loc1 = Process(name='com1_receive_loc1', prod_max=com1_process_capacity, conversion={com1_loc1_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 1')\n",
    "    com1_receive_loc2 = Process(name='com1_receive_loc2', prod_max=com1_process_capacity, conversion={com1_loc2_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 2')\n",
    "    com1_receive_loc3 = Process(name='com1_receive_loc3', prod_max=com1_process_capacity, conversion={com1_loc3_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 3')\n",
    "    com1_receive_loc4 = Process(name='com1_receive_loc4', prod_max=com1_process_capacity, conversion={com1_loc4_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 4')\n",
    "    com1_receive_loc5 = Process(name='com1_receive_loc5', prod_max=com1_process_capacity, conversion={com1_loc5_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 5')\n",
    "    com1_receive_loc6 = Process(name='com1_receive_loc6', prod_max=com1_process_capacity, conversion={com1_loc6_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 6')\n",
    "    com1_receive_loc7 = Process(name='com1_receive_loc7', prod_max=com1_process_capacity, conversion={com1_loc7_out:-1, com1_in:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Commodity 1 received from location 7')\n",
    "    \n",
    "    com1_process = Process(name='com1_process', prod_max=com1_process_capacity, conversion={com1_in: -1, com1_out: 1},  capex=5, vopex=0.01, prod_min=0.01, label='Process the commodity through the location', varying=[VaryingProcess.DETERMINISTIC_CAPACITY])\n",
    "    \n",
    "    # com1_process = Process(name='com1_process', prod_max=prod_max, conversion={0:{com1_in: -1, com1_out: 1}, 1:{com1_in: -1, com1_out: 1}, 2:{com1_in: -1, com1_out: 1}, 3:{com1_in: -1, com1_out: 1}, 4:{com1_in: -1, com1_out: 1}},  capex=0.01, vopex=0.01, prod_min=prod_min, rate_max=rate_max, varying=[VaryingProcess.DETERMINISTIC_CAPACITY], label='Process the commodity through the location')\n",
    "    \n",
    "    # com1_store10 = Process(name='com1_store10', prod_max=com1_process_capacity, capex=0.1, vopex=0.01, storage_capex=10, store_min=0.01, store_max= 40, prod_min=0.01, label=\"Storage capacity of 10 units\", storage=com1_in, storage_cost=0.02)\n",
    "    # com1_store20 = Process(name='com1_store20', prod_max=com1_process_capacity, capex=0.1, vopex=0.02, storage_capex=20, store_min=0.01,store_max= 80, prod_min=0.01, label=\"Storage capacity of 20 units\", storage=com1_in, storage_cost=0.02)\n",
    "    # com1_store50 = Process(name='com1_store50', prod_max=com1_process_capacity, capex=0.1, vopex=0.05, storage_capex=50, store_min=0.01, store_max= 200, prod_min=0.01, label=\"Storage capacity of 50 units\", storage=com1_in, storage_cost=0.02)\n",
    "    \n",
    "    com1_store = Process(name='com1_store', prod_max=500, capex=0.5, vopex=0.01, storage_capex=30, store_min=0.01, store_max=200, prod_min=0.01, label=\"Storage process\", storage=com1_in, storage_cost=0.02)\n",
    "    \n",
    "    com1_loc1_send = Process(name='com1_loc1_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc1_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 1')\n",
    "    com1_loc2_send = Process(name='com1_loc2_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc2_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 2')\n",
    "    com1_loc3_send = Process(name='com1_loc3_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc3_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 3')\n",
    "    com1_loc4_send = Process(name='com1_loc4_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc4_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 4')\n",
    "    com1_loc5_send = Process(name='com1_loc5_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc5_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 5')\n",
    "    com1_loc6_send = Process(name='com1_loc6_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc6_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 6')\n",
    "    com1_loc7_send = Process(name='com1_loc7_send', prod_max=com1_process_capacity, conversion={com1_out:-1, com1_loc7_out:1}, capex=0.1, vopex=0.01, prod_min=0.01, label='Send commodity one from location 7')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ======================================================================================================================\n",
    "    # Declare locations/warehouses\n",
    "    # ======================================================================================================================\n",
    "    loc1 = Location(name='loc1', processes={com1_procure, com1_receive_loc2, com1_receive_loc3, com1_process, com1_store, com1_loc1_send}, label=\"Location 1\",\n",
    "    scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1, \n",
    "    availability_factor={com1_pur: scen_df[[('loc1', 'com1_pur')]] if ('loc1', 'com1_pur') in scen_df else default_df})\n",
    "    \n",
    "    loc2 = Location(name='loc2', processes={com1_receive_loc1, com1_receive_loc4, com1_receive_loc5, com1_process, com1_store, com1_loc2_send}, label=\"Location 2\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1,\n",
    "    capacity_factor={com1_process: scen_df[[('loc2', 'com1_process')]] if ('loc2', 'com1_process') in scen_df else default_df})\n",
    "    \n",
    "    loc3 = Location(name='loc3', processes={com1_receive_loc1, com1_receive_loc4, com1_process, com1_store, com1_loc3_send}, label=\"Location 3\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1)\n",
    "    \n",
    "    loc4 = Location(name='loc4', processes={com1_receive_loc2, com1_receive_loc3, com1_receive_loc6, com1_receive_loc5, com1_receive_loc7, com1_process, com1_store, com1_loc4_send}, label=\"Location 4\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1,\n",
    "    capacity_factor={com1_process: scen_df[[('loc4', 'com1_process')]] if ('loc4', 'com1_process') in scen_df else default_df})\n",
    "    \n",
    "    loc5 = Location(name='loc5', processes={com1_receive_loc2, com1_receive_loc4, com1_receive_loc7, com1_process, com1_store, com1_loc5_send, com1_sell}, label=\"Location 5\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1)\n",
    "    \n",
    "    loc6 = Location(name='loc6', processes={com1_procure, com1_receive_loc4, com1_process, com1_store, com1_loc6_send}, label=\"Location 6\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1,\n",
    "    availability_factor={com1_pur: scen_df[[('loc6', 'com1_pur')]] if ('loc6', 'com1_pur') in scen_df else default_df})\n",
    "    \n",
    "    loc7 = Location(name='loc7', processes={com1_receive_loc4, com1_receive_loc5, com1_process, com1_store, com1_loc7_send}, label=\"Location 7\", scales=scales, demand_scale_level=2, capacity_scale_level=1, availability_scale_level=1,\n",
    "    capacity_factor={com1_process: scen_df[[('loc7', 'com1_process')]] if ('loc7', 'com1_process') in scen_df else default_df})\n",
    "    \n",
    "    \n",
    "    # ======================================================================================================================\n",
    "    # Declare transport/trucks\n",
    "    # ======================================================================================================================\n",
    "    \n",
    "    truck_cap12 = 4*70\n",
    "    truck_cap13 = 9*30\n",
    "    truck_cap24 = 9*50\n",
    "    truck_cap25 = 9*30\n",
    "    truck_cap34 = 9*30\n",
    "    truck_cap45 = 5*100\n",
    "    truck_cap47 = 9*40\n",
    "    truck_cap64 = 9*50\n",
    "    truck_cap75 = 9*40\n",
    "    \n",
    "    truck12 = Transport(name='truck12', resources={com1_loc1_out}, trans_max=truck_cap12, label='Truck from location 1 to 2', capex=0.5, vopex=0.05, trans_min=0.01)\n",
    "    truck21 = Transport(name='truck21', resources={com1_loc2_out}, trans_max=truck_cap12, label='Truck from location 2 to 1', capex=0.0001, vopex=0.05, trans_min=0.01)\n",
    "    \n",
    "    truck13 = Transport(name='truck13', resources={com1_loc1_out}, trans_max=truck_cap13, label='Truck from location 1 to 3', capex=0.3, vopex=0.03, trans_min=0.01)\n",
    "    truck31 = Transport(name='truck31', resources={com1_loc3_out}, trans_max=truck_cap13, label='Truck from location 3 to 1', capex=0.0001, vopex=0.03, trans_min=0.01)\n",
    "    \n",
    "    truck24 = Transport(name='truck24', resources={com1_loc2_out}, trans_max=truck_cap24, label='Truck from location 2 to 4', capex=0.5, vopex=0.05, trans_min=0.01)\n",
    "    truck42 = Transport(name='truck42', resources={com1_loc4_out}, trans_max=truck_cap24, label='Truck from location 4 to 2', capex=0.0001, vopex=0.05, trans_min=0.01)\n",
    "    \n",
    "    truck25 = Transport(name='truck25', resources={com1_loc2_out}, trans_max=truck_cap25, label='Truck from location 2 to 5', capex=0.3, vopex=0.03, trans_min=0.01)\n",
    "    truck52 = Transport(name='truck52', resources={com1_loc5_out}, trans_max=truck_cap25, label='Truck from location 5 to 2', capex=0.0001, vopex=0.03, trans_min=0.01)\n",
    "    \n",
    "    truck34 = Transport(name='truck34', resources={com1_loc3_out}, trans_max=truck_cap34, label='Truck from location 3 to 4', capex=0.2, vopex=0.02, trans_min=0.01)\n",
    "    truck43 = Transport(name='truck43', resources={com1_loc4_out}, trans_max=truck_cap34, label='Truck from location 4 to 3', capex=0.0001, vopex=0.02, trans_min=0.01)\n",
    "    \n",
    "    truck45 = Transport(name='truck45', resources={com1_loc4_out}, trans_max=truck_cap45, label='Truck from location 4 to 5', capex=1, vopex=0.1, trans_min=0.01)\n",
    "    truck54 = Transport(name='truck54', resources={com1_loc5_out}, trans_max=truck_cap45, label='Truck from location 5 to 4', capex=0.0001, vopex=0.1, trans_min=0.01)\n",
    "    \n",
    "    truck47 = Transport(name='truck47', resources={com1_loc4_out}, trans_max=truck_cap47, label='Truck from location 4 to 7', capex=0.4, vopex=0.04, trans_min=0.01)\n",
    "    truck74 = Transport(name='truck74', resources={com1_loc7_out}, trans_max=truck_cap47, label='Truck from location 7 to 4', capex=0.0001, vopex=0.04, trans_min=0.01)\n",
    "    \n",
    "    truck64 = Transport(name='truck64', resources={com1_loc6_out}, trans_max=truck_cap64, label='Truck from location 6 to 4', capex=0.5, vopex=0.05, trans_min=0.01)\n",
    "    truck46 = Transport(name='truck46', resources={com1_loc4_out}, trans_max=truck_cap64, label='Truck from location 4 to 6', capex=0.0001, vopex=0.05, trans_min=0.01)\n",
    "    \n",
    "    truck75 = Transport(name='truck75', resources={com1_loc7_out}, trans_max=truck_cap75, label='Truck from location 7 to 5', capex=0.4, vopex=0.04, trans_min=0.01)\n",
    "    truck57 = Transport(name='truck57', resources={com1_loc5_out}, trans_max=truck_cap75, label='Truck from location 5 to 7', capex=0.0001, vopex=0.04, trans_min=0.01)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ======================================================================================================================\n",
    "    # Declare network\n",
    "    # ======================================================================================================================\n",
    "    \n",
    "    transport_matrix = [\n",
    "        [[], [truck12], [truck13], [], [], [], []],  # source: location 1\n",
    "        [[truck21], [], [], [truck24], [truck25], [], []],  # source: location 2\n",
    "        [[truck31], [], [], [truck34], [], [], []],  # source: location 3\n",
    "        [[], [truck42], [truck43], [], [truck45], [truck46], [truck47]],  # source: location 4\n",
    "        [[], [truck52], [], [truck54], [], [], [truck57]],  # source: location 5\n",
    "        [[], [], [], [truck64], [], [], []],  # source: location 6\n",
    "        [[], [], [], [truck74], [truck75], [], []]  # source: location 7\n",
    "    ]\n",
    "    \n",
    "    distance_matrix = [\n",
    "        [0, 55, 196, M, M, M, M],\n",
    "        [55, 0, M, 163, 112, M, 134],\n",
    "        [196, M, 0, 63, M, M, M],\n",
    "        [M, 163, 63, 0, 95, 117, 88],\n",
    "        [M, 112, M, 95, 0, M, 134],\n",
    "        [M, M, M, 117, M, 0, M],\n",
    "        [M, 134, M, 88, 134, M, 0]\n",
    "    ]\n",
    "    \n",
    "    locset = [loc1, loc2, loc3, loc4, loc5, loc6, loc7]\n",
    "    \n",
    "    sources = locset\n",
    "    sinks = locset\n",
    "    \n",
    "    network = Network(name='Network', scales= scales, source_locations=sources, sink_locations=sinks, transport_matrix=transport_matrix, distance_matrix=distance_matrix)\n",
    "\n",
    "\n",
    "\n",
    "    # ======================================================================================================================\n",
    "    # Declare scenario\n",
    "    # ======================================================================================================================\n",
    "    \n",
    "    daily_demand = 400\n",
    "    demand_penalty = 20\n",
    "    \n",
    "    demand_dict = {i: {com1_sold: daily_demand} if i == loc5 else {com1_sold: 0} for i in locset}\n",
    "    demand_penalty_dict = {i: {com1_sold: demand_penalty} if i == loc5 else {com1_sold: 0} for i in locset}\n",
    "    \n",
    "    scenario = Scenario(name='scenario', scales=scales, scheduling_scale_level=2, network_scale_level=0, purchase_scale_level=2, availability_scale_level=1, demand_scale_level=2, capacity_scale_level=1, network=network, demand=demand_dict, demand_penalty=demand_penalty_dict, label='Stochastic scenario with Multiple Locations')\n",
    "    \n",
    "    if scen_df.empty:\n",
    "        # ======================================================================================================================\n",
    "        # Declare problem\n",
    "        # ======================================================================================================================\n",
    "        \n",
    "        problem_mincost = formulate(scenario=scenario,\n",
    "                                constraints={Constraints.COST, Constraints.TRANSPORT, Constraints.RESOURCE_BALANCE, Constraints.INVENTORY, Constraints.PRODUCTION, Constraints.DEMAND, Constraints.NETWORK},\n",
    "                                demand_sign='eq', objective=Objective.COST_W_DEMAND_PENALTY)\n",
    "        \n",
    "\n",
    "        scale_iter = scale_tuple(instance=problem_mincost, scale_levels=scenario.network_scale_level+1)\n",
    "        capex_process= sum(problem_mincost.Capex_network[scale_] for scale_ in scale_iter)\n",
    "        cost_trans_capex = sum(problem_mincost.Capex_transport_network[scale_] for scale_ in scale_iter)\n",
    "\n",
    "        problem_mincost.first_stage_cost  = capex_process + cost_trans_capex\n",
    "        \n",
    "        return scenario, problem_mincost\n",
    "    \n",
    "    else:\n",
    "        return scenario"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.506354Z",
     "start_time": "2024-09-18T14:27:16.475879Z"
    }
   },
   "id": "e19a5b3b71979c5b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scen_test, problem_test = build_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.521834Z",
     "start_time": "2024-09-18T14:27:16.508422Z"
    }
   },
   "id": "6795e7cc1c242cee",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.537288Z",
     "start_time": "2024-09-18T14:27:16.522877Z"
    }
   },
   "id": "d5df324af12891e4",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# problem_test.constraint_nameplate_production_varying_capacity.pprint()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.552803Z",
     "start_time": "2024-09-18T14:27:16.538381Z"
    }
   },
   "id": "90bd8b8c5468f884",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scen_test.capacity_factor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.568454Z",
     "start_time": "2024-09-18T14:27:16.553804Z"
    }
   },
   "id": "b6f79a4f601f9177",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# problem_test.del_component('constraint_nameplate_production_varying_capacity')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.583419Z",
     "start_time": "2024-09-18T14:27:16.569463Z"
    }
   },
   "id": "c3e0e383850745",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Solver Options"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45c7c6a0048c97c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "solver_options = {\n",
    "    'MIPGap': 0.005,\n",
    "    # 'TimeLimit': 60 * 15,\n",
    "    'Heuristics': 0.20\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:27:16.599228Z",
     "start_time": "2024-09-18T14:27:16.584493Z"
    }
   },
   "id": "682a7ef115b21bd8",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perfect Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5d8482d93a80e9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exCost_PI = 0\n",
    "results_PI = dict()\n",
    "scen_PI, model_PI = build_model()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33d28a1900569cbf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint process capex\n",
      "constraint process fopex\n",
      "constraint process vopex\n",
      "constraint process incidental\n",
      "constraint location capex\n",
      "constraint location fopex\n",
      "constraint storage cost\n",
      "constraint storage capex\n",
      "constraint storage cost location\n",
      "constraint storage cost network\n",
      "constraint production mode\n",
      "constraint inventory balance\n",
      "constraint inventory network\n",
      "constraint resource export\n",
      "constraint transport export\n",
      "constraint export\n",
      "constraint transport capex\n",
      "constraint transport network capex\n",
      "constraint transport export network\n",
      "constraint transport vopex\n",
      "constraint transport network vopex\n",
      "constraint transport fopex\n",
      "constraint transport network fopex\n",
      "constraint transport capacity UB no bin\n",
      "constraint transport capacity LB no bin\n",
      "constraint storage facility\n",
      "constraint production facility\n",
      "constraint min production facility\n",
      "constraint min storage facility\n",
      "constraint transport capacity UB\n",
      "constraint transport capacity LB\n",
      "constraint demand penalty\n",
      "constraint demand penalty location\n",
      "constraint demand penalty network\n",
      "constraint demand penalty cost\n",
      "constraint demand penalty cost location\n",
      "constraint demand penalty cost network\n",
      "objective cost w demand penalty\n",
      "Set parameter MIPGap to value 0.005\n",
      "Set parameter TimeLimit to value 900\n",
      "Set parameter Heuristics to value 0.2\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 883012 rows, 2814283 columns and 1166864 nonzeros\n",
      "Model fingerprint: 0xf011f734\n",
      "Variable types: 2813261 continuous, 1022 integer (1022 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-03, 5e+02]\n",
      "  Objective range  [1e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+02, 1e+03]\n",
      "Presolve removed 842733 rows and 2774277 columns\n",
      "Presolve time: 0.18s\n",
      "Presolved: 40279 rows, 40006 columns, 130055 nonzeros\n",
      "Variable types: 39932 continuous, 74 integer (74 binary)\n",
      "Found heuristic solution: objective 2912000.0000\n",
      "\n",
      "Root relaxation: objective 2.059367e+06, 7221 iterations, 0.20 seconds (0.29 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    2059367.3000 2059367.30  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (7221 simplex iterations) in 0.93 seconds (1.50 work units)\n",
      "Thread count was 24 (of 24 available processors)\n",
      "\n",
      "Solution count 2: 2.05937e+06 2.912e+06 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-03)\n",
      "Best objective 2.059367300000e+06, best bound 2.059367300000e+06, gap 0.0000%\n",
      "WARNING: Cannot get duals for MIP.\n",
      "######################## Finished solving cap2_13 ########################\n",
      "constraint process capex\n",
      "constraint process fopex\n",
      "constraint process vopex\n",
      "constraint process incidental\n",
      "constraint location capex\n",
      "constraint location fopex\n",
      "constraint storage cost\n",
      "constraint storage capex\n",
      "constraint storage cost location\n",
      "constraint storage cost network\n",
      "constraint production mode\n",
      "constraint inventory balance\n",
      "constraint inventory network\n",
      "constraint resource export\n",
      "constraint transport export\n",
      "constraint export\n",
      "constraint transport capex\n",
      "constraint transport network capex\n",
      "constraint transport export network\n",
      "constraint transport vopex\n",
      "constraint transport network vopex\n",
      "constraint transport fopex\n",
      "constraint transport network fopex\n",
      "constraint transport capacity UB no bin\n",
      "constraint transport capacity LB no bin\n",
      "constraint storage facility\n",
      "constraint production facility\n",
      "constraint min production facility\n",
      "constraint min storage facility\n",
      "constraint transport capacity UB\n",
      "constraint transport capacity LB\n",
      "constraint demand penalty\n",
      "constraint demand penalty location\n",
      "constraint demand penalty network\n",
      "constraint demand penalty cost\n",
      "constraint demand penalty cost location\n",
      "constraint demand penalty cost network\n",
      "objective cost w demand penalty\n",
      "Set parameter MIPGap to value 0.005\n",
      "Set parameter TimeLimit to value 900\n",
      "Set parameter Heuristics to value 0.2\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 883012 rows, 2814283 columns and 1166955 nonzeros\n",
      "Model fingerprint: 0x0edbf441\n",
      "Variable types: 2813261 continuous, 1022 integer (1022 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-03, 5e+02]\n",
      "  Objective range  [1e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+02, 1e+03]\n",
      "Presolve removed 841550 rows and 2772639 columns\n",
      "Presolve time: 0.18s\n",
      "Presolved: 41462 rows, 41644 columns, 134241 nonzeros\n",
      "Variable types: 41570 continuous, 74 integer (74 binary)\n",
      "Found heuristic solution: objective 2912000.0000\n",
      "\n",
      "Root relaxation: objective 1.844689e+06, 8031 iterations, 0.15 seconds (0.24 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    1844689.2000 1844689.20  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (8031 simplex iterations) in 0.85 seconds (1.48 work units)\n",
      "Thread count was 24 (of 24 available processors)\n",
      "\n",
      "Solution count 2: 1.84469e+06 2.912e+06 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-03)\n",
      "Best objective 1.844689200000e+06, best bound 1.844689200000e+06, gap 0.0000%\n",
      "WARNING: Cannot get duals for MIP.\n",
      "######################## Finished solving cap2_26 ########################\n",
      "constraint process capex\n",
      "constraint process fopex\n",
      "constraint process vopex\n",
      "constraint process incidental\n",
      "constraint location capex\n",
      "constraint location fopex\n",
      "constraint storage cost\n",
      "constraint storage capex\n",
      "constraint storage cost location\n",
      "constraint storage cost network\n",
      "constraint production mode\n",
      "constraint inventory balance\n",
      "constraint inventory network\n",
      "constraint resource export\n",
      "constraint transport export\n",
      "constraint export\n",
      "constraint transport capex\n",
      "constraint transport network capex\n",
      "constraint transport export network\n",
      "constraint transport vopex\n",
      "constraint transport network vopex\n",
      "constraint transport fopex\n",
      "constraint transport network fopex\n",
      "constraint transport capacity UB no bin\n",
      "constraint transport capacity LB no bin\n",
      "constraint storage facility\n",
      "constraint production facility\n",
      "constraint min production facility\n",
      "constraint min storage facility\n",
      "constraint transport capacity UB\n",
      "constraint transport capacity LB\n",
      "constraint demand penalty\n",
      "constraint demand penalty location\n",
      "constraint demand penalty network\n",
      "constraint demand penalty cost\n",
      "constraint demand penalty cost location\n",
      "constraint demand penalty cost network\n",
      "objective cost w demand penalty\n",
      "Set parameter MIPGap to value 0.005\n",
      "Set parameter TimeLimit to value 900\n",
      "Set parameter Heuristics to value 0.2\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 883012 rows, 2814283 columns and 1167046 nonzeros\n",
      "Model fingerprint: 0x4a1f6a46\n",
      "Variable types: 2813261 continuous, 1022 integer (1022 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-03, 5e+02]\n",
      "  Objective range  [1e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+02, 1e+03]\n",
      "Presolve removed 840367 rows and 2771001 columns\n",
      "Presolve time: 0.19s\n",
      "Presolved: 42645 rows, 43282 columns, 138427 nonzeros\n",
      "Variable types: 43208 continuous, 74 integer (74 binary)\n",
      "Found heuristic solution: objective 2912000.0000\n",
      "\n",
      "Root relaxation: objective 1.630011e+06, 9401 iterations, 0.19 seconds (0.31 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    1630011.1000 1630011.10  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (9401 simplex iterations) in 0.93 seconds (1.57 work units)\n",
      "Thread count was 24 (of 24 available processors)\n",
      "\n",
      "Solution count 2: 1.63001e+06 2.912e+06 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-03)\n",
      "Best objective 1.630011100000e+06, best bound 1.630011100000e+06, gap 0.0000%\n",
      "WARNING: Cannot get duals for MIP.\n",
      "######################## Finished solving cap2_39 ########################\n",
      "constraint process capex\n",
      "constraint process fopex\n",
      "constraint process vopex\n",
      "constraint process incidental\n",
      "constraint location capex\n",
      "constraint location fopex\n",
      "constraint storage cost\n",
      "constraint storage capex\n",
      "constraint storage cost location\n",
      "constraint storage cost network\n",
      "constraint production mode\n",
      "constraint inventory balance\n",
      "constraint inventory network\n",
      "constraint resource export\n",
      "constraint transport export\n",
      "constraint export\n",
      "constraint transport capex\n",
      "constraint transport network capex\n",
      "constraint transport export network\n",
      "constraint transport vopex\n",
      "constraint transport network vopex\n",
      "constraint transport fopex\n",
      "constraint transport network fopex\n",
      "constraint transport capacity UB no bin\n",
      "constraint transport capacity LB no bin\n",
      "constraint storage facility\n",
      "constraint production facility\n",
      "constraint min production facility\n",
      "constraint min storage facility\n",
      "constraint transport capacity UB\n",
      "constraint transport capacity LB\n",
      "constraint demand penalty\n",
      "constraint demand penalty location\n",
      "constraint demand penalty network\n",
      "constraint demand penalty cost\n",
      "constraint demand penalty cost location\n",
      "constraint demand penalty cost network\n",
      "objective cost w demand penalty\n",
      "Set parameter MIPGap to value 0.005\n",
      "Set parameter TimeLimit to value 900\n",
      "Set parameter Heuristics to value 0.2\n",
      "Set parameter QCPDual to value 1\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 883012 rows, 2814283 columns and 1167137 nonzeros\n",
      "Model fingerprint: 0x974d44bd\n",
      "Variable types: 2813261 continuous, 1022 integer (1022 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [6e-03, 5e+02]\n",
      "  Objective range  [1e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+02, 1e+03]\n",
      "Presolve removed 839184 rows and 2769363 columns\n",
      "Presolve time: 0.24s\n",
      "Presolved: 43828 rows, 44920 columns, 142613 nonzeros\n",
      "Variable types: 44846 continuous, 74 integer (74 binary)\n",
      "Found heuristic solution: objective 2912000.0000\n",
      "\n",
      "Root relaxation: objective 1.364560e+06, 12803 iterations, 0.64 seconds (0.84 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    1364560.0000 1364560.00  0.00%     -    1s\n",
      "\n",
      "Explored 1 nodes (12803 simplex iterations) in 1.50 seconds (2.12 work units)\n",
      "Thread count was 24 (of 24 available processors)\n",
      "\n",
      "Solution count 2: 1.36456e+06 2.912e+06 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-03)\n",
      "Best objective 1.364560000000e+06, best bound 1.364560000000e+06, gap 0.0000%\n",
      "WARNING: Cannot get duals for MIP.\n",
      "######################## Finished solving cap2_52 ########################\n"
     ]
    }
   ],
   "source": [
    "for scen_name in scenario_names:\n",
    "    scen_PI = build_model(scen_df=scenario_dict[scen_name]['factor'])\n",
    "    \n",
    "    # Delete process capacity factors, resource availability factors, transport capacity factors\n",
    "    model_PI.del_component('constraint_nameplate_production_varying_capacity')\n",
    "    model_PI.del_component('constraint_resource_consumption_varying')\n",
    "    model_PI.del_component('constraint_export')\n",
    "    \n",
    "    # print(scen_PI.capacity_factor)\n",
    "    # print(scen_PI.availability_factor)\n",
    "    # print(scen_PI.transport_capacity_factor)\n",
    "    \n",
    "    # Add the constraints back for this particular scenario\n",
    "    model_PI.constraint_nameplate_production_varying_capacity = make_constraint(instance=model_PI, type_cons=Cons.X_LEQ_BY, variable_x='P', location_set=model_PI.locations, component_set=model_PI.processes_varying_capacity,  loc_comp_dict=scen_PI.location_process_dict, b_factor=scen_PI.capacity_factor, x_scale_level=scen_PI.scheduling_scale_level, b_scale_level=scen_PI.capacity_scale_level, y_scale_level=scen_PI.network_scale_level, variable_y='Cap_P', label='restricts production to varying nameplate capacity')\n",
    "    \n",
    "    model_PI.constraint_resource_consumption_varying = make_constraint(\n",
    "                instance=model_PI, type_cons=Cons.X_LEQ_B, variable_x='C', location_set=model_PI.locations, component_set=model_PI.resources_varying_availability, b_max=scen_PI.cons_max,\n",
    "                loc_comp_dict=scen_PI.location_resource_dict, b_factor=scen_PI.availability_factor, x_scale_level=scen_PI.scheduling_scale_level, b_scale_level=scen_PI.availability_scale_level, label='restricts resource consumption to varying availablity')\n",
    "    \n",
    "    constraint_export(instance=model_PI, scheduling_scale_level=scen_PI.scheduling_scale_level,\n",
    "    network_scale_level=scen_PI.network_scale_level, location_transport_resource_dict=scen_PI.location_transport_resource_dict, transport_capacity_factor=scen_PI.transport_capacity_factor, transport_capacity_scale_level=scen_PI.transport_capacity_scale_level)\n",
    "\n",
    "    results_PI = solve(scenario=scen_PI, instance=model_PI, solver='gurobi', name=scen_name, solver_options=solver_options)\n",
    "    \n",
    "    print('######################## Finished solving '+scen_name+' ########################')\n",
    "    \n",
    "    exCost_PI += value(model_PI.objective_cost_w_demand_penalty)*scenario_dict[scen_name]['prob']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:32:20.137155Z",
     "start_time": "2024-09-18T14:27:16.600263Z"
    }
   },
   "id": "b9caa799bc017847",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1487130.9500000002"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exCost_PI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T14:32:20.152698Z",
     "start_time": "2024-09-18T14:32:20.138170Z"
    }
   },
   "id": "1a7581470735c64d",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Expected Value of Perfect Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5c9a840986e1a3a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scenario_creator(scenario_name):  \n",
    "    scen, model = build_model(scen_df=scenario_dict[scenario_name]['factor'])\n",
    "    sputils.attach_root_node(model, model.first_stage_cost, [model.X_P, model.Cap_P, model.X_S, model.Cap_S, model.X_F, model.Cap_F])\n",
    "    model._mpisppy_probability = scenario_dict[scenario_name]['prob']\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570e0330063017ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mpisppy.opt.ef import ExtensiveForm\n",
    "options = {\"solver\": \"gurobi\"}\n",
    "# all_scenario_names = [\"good\", \"average\", \"bad\"]\n",
    "ef_UI = ExtensiveForm(options, scenario_names, scenario_creator)\n",
    "results = ef_UI.solve_extensive_form(solver_options=solver_options)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2f11fb6c4aee764",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exCost_UI = ef_UI.get_objective_value()\n",
    "print(f\"{exCost_UI:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1104ef40f9ba8f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EVPI = exCost_UI - exCost_PI\n",
    "EVPI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3288f44b03fba042",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "p_inc = EVPI*100/exCost_PI\n",
    "p_inc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47d6ca637e865a1c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ssoln_dict = ef_UI.get_root_solution()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44bd80a8e386aa86",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Value of Stochastic Solution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460ed5cbbe5dc9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# n_avg = int(sum(ns_dict[i] for i in ns_dict.keys())/3)\n",
    "# cap_factor_avg = pandas.DataFrame(data={'com1_process': [1]*n_avg + [0]*(_exec_scenarios-n_avg)})\n",
    "# scen_avg, model_avg = build_model(cap_factor=cap_factor_avg)\n",
    "# \n",
    "# solver_avg = SolverFactory(\"gurobi\")\n",
    "# solver_avg.solve(model_avg, options=solver_options)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d323c45bb9f268",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def fix_variables(model1: ConcreteModel, model2:ConcreteModel):\n",
    "#     \n",
    "#     def fix(var1, var2):\n",
    "#         for i in list(var1.keys()):\n",
    "#             if var1[i].value is None:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 var2[i].fixed = True\n",
    "#                 var2[i] = value(var1[i])\n",
    "#             # var2[i].pprint()\n",
    "#             \n",
    "#     fix(model1.X_P, model2.X_P)\n",
    "#     fix(model1.Cap_P, model2.Cap_P)\n",
    "#     fix(model1.X_S, model2.X_S)\n",
    "#     fix(model1.Cap_S, model2.Cap_S)\n",
    "#     fix(model1.X_F, model2.X_F)\n",
    "#     fix(model1.Cap_F, model2.Cap_F)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e600e1fd37c89d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# exCost_FD = 0\n",
    "# \n",
    "# for scenario_name in all_scenario_names:\n",
    "#     cap_factor_VSS = pandas.DataFrame(data={'com1_process': [1]*ns_dict[scenario_name] + [0]*(_exec_scenarios-ns_dict[scenario_name])})\n",
    "#     scen_VSS, model_VSS = build_model(cap_factor=cap_factor_VSS)\n",
    "#     \n",
    "#     fix_variables(model1=model_avg, model2=model_VSS)\n",
    "#     \n",
    "#     solver_VSS = SolverFactory(\"gurobi\")\n",
    "#     solver_VSS.solve(model_VSS, options=solver_options)\n",
    "#     \n",
    "#     print('######################## Finished solving '+scenario_name+' ########################')\n",
    "#     \n",
    "#     exCost_FD += value(model_VSS.objective_cost_w_demand_penalty)*scenario_probabilities[scenario_name]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6abb12db1ec380d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# VSS = exCost_FD - exCost_UI\n",
    "# VSS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fe1afbf041197f5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results Summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb5e0c2cf2412bf6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define nodes (suppliers, factories, warehouses, etc.) with additional labels\n",
    "nodes = {\n",
    "    'Location 1': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc1,com1_process,0]'] if 'Cap_P[loc1,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc1,com1_store,0]'] if 'Cap_P[loc1, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 2': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc2,com1_process,0]'] if 'Cap_P[loc2,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc2,com1_store,0]'] if 'Cap_P[loc2, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 3': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc3,com1_process,0]'] if 'Cap_P[loc3,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc3,com1_store,0]'] if 'Cap_P[loc3, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 4': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc4,com1_process,0]'] if 'Cap_P[loc4,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc4,com1_store,0]'] if 'Cap_P[loc4, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 5': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc5,com1_process,0]'] if 'Cap_P[loc5,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc5,com1_store,0]'] if 'Cap_P[loc5, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 6': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc6,com1_process,0]'] if 'Cap_P[loc6,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc6,com1_store,0]'] if 'Cap_P[loc6, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "    'Location 7': {\n",
    "        'Capacity': ssoln_dict['Cap_P[loc7,com1_process,0]'] if 'Cap_P[loc7,com1_process,0]' in ssoln_dict.keys() else 0,\n",
    "        'Inventory': ssoln_dict['Cap_P[loc7,com1_store,0]'] if 'Cap_P[loc7, com1_store,0]' in ssoln_dict.keys() else 0\n",
    "    },\n",
    "}\n",
    "\n",
    "# Add nodes to the graph\n",
    "G.add_nodes_from(nodes.keys())\n",
    "\n",
    "# Define edges (connections between nodes)\n",
    "edges = [\n",
    "    ('Location 1', 'Location 2', {'weight': ssoln_dict['Cap_F[loc1,loc2,truck12,0]'] if 'Cap_F[loc1,loc2,truck12,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 1', 'Location 3', {'weight': ssoln_dict['Cap_F[loc1,loc3,truck13,0]'] if 'Cap_F[loc1,loc3,truck13,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 2', 'Location 4', {'weight': ssoln_dict['Cap_F[loc2,loc4,truck24,0]'] if 'Cap_F[loc2,loc4,truck24,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 2', 'Location 5', {'weight': ssoln_dict['Cap_F[loc2,loc5,truck25,0]'] if 'Cap_F[loc2,loc5,truck25,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 3', 'Location 4', {'weight': ssoln_dict['Cap_F[loc3,loc4,truck34,0]'] if 'Cap_F[loc3,loc4,truck34,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 4', 'Location 5', {'weight': ssoln_dict['Cap_F[loc4,loc5,truck45,0]'] if 'Cap_F[loc4,loc5,truck45,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 4', 'Location 7', {'weight': ssoln_dict['Cap_F[loc4,loc7,truck47,0]'] if 'Cap_F[loc4,loc7,truck47,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 6', 'Location 4', {'weight': ssoln_dict['Cap_F[loc6,loc4,truck64,0]'] if 'Cap_F[loc6,loc4,truck64,0]' in ssoln_dict.keys() else 0}),\n",
    "    ('Location 7', 'Location 5', {'weight': ssoln_dict['Cap_F[loc7,loc5,truck75,0]'] if 'Cap_F[loc7,loc5,truck75,0]' in ssoln_dict.keys() else 0}),\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Define fixed positions for nodes\n",
    "fixed_positions = {\n",
    "    'Location 1': (-2, 2),\n",
    "    'Location 2': (0, 2),\n",
    "    'Location 3': (-2, 0),\n",
    "    'Location 4': (0, 0),\n",
    "    'Location 5': (2, 0),\n",
    "    'Location 6': (-2, -2),\n",
    "    'Location 7': (1, -2)\n",
    "}\n",
    "\n",
    "# Create custom labels combining multiple pieces of information\n",
    "node_labels = {node: f\"Capacity: {data['Capacity']}\\nInventory: {data['Inventory']}\" for node, data in nodes.items()}\n",
    "\n",
    "# Draw nodes and edges with fixed positions\n",
    "nx.draw_networkx_nodes(G, fixed_positions, node_color='skyblue', node_size=700)\n",
    "nx.draw_networkx_edges(G, fixed_positions, edgelist=edges, arrowstyle='simple', arrowsize=20)\n",
    "nx.draw_networkx_labels(G, fixed_positions, labels=node_labels, font_size=8, font_color='green', font_weight='bold')\n",
    "\n",
    "# Draw edge labels (optional)\n",
    "edge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\n",
    "nx.draw_networkx_edge_labels(G, fixed_positions, edge_labels=edge_labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Supply Chain Network with Fixed Node Positions\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fa4e957123818c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EVPI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab0d07ed8eefb56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "p_inc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c16923348bedc9c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "# \n",
    "# # Create a directed graph\n",
    "# G = nx.DiGraph()\n",
    "# \n",
    "# # Define nodes with additional labels\n",
    "# nodes = {\n",
    "#     'Supplier1': {'type': 'Supplier', 'inventory': 100},\n",
    "#     'Supplier2': {'type': 'Supplier', 'inventory': 150},\n",
    "#     'Factory': {'type': 'Factory', 'inventory': 200},\n",
    "#     'Warehouse': {'type': 'Warehouse', 'inventory': 300},\n",
    "#     'Customer': {'type': 'Customer', 'inventory': 0}\n",
    "# }\n",
    "# \n",
    "# # Add nodes and edges to the graph\n",
    "# G.add_nodes_from(nodes.keys())\n",
    "# edges = [\n",
    "#     ('Supplier1', 'Factory', {'weight': 10}),\n",
    "#     ('Supplier2', 'Factory', {'weight': 15}),\n",
    "#     ('Factory', 'Warehouse', {'weight': 20}),\n",
    "#     ('Warehouse', 'Customer', {'weight': 25}),\n",
    "# ]\n",
    "# G.add_edges_from(edges)\n",
    "# \n",
    "# # Define fixed positions for nodes\n",
    "# fixed_positions = {\n",
    "#     'Supplier1': (-1, 1),\n",
    "#     'Supplier2': (-1, -1),\n",
    "#     'Factory': (0, 0),\n",
    "#     'Warehouse': (1, 0),\n",
    "#     'Customer': (2, 0)\n",
    "# }\n",
    "# \n",
    "# # Create custom labels combining multiple pieces of information\n",
    "# node_labels = {node: f\"{data['type']}\\nInventory: {data['inventory']}\" for node, data in nodes.items()}\n",
    "# \n",
    "# # Draw nodes and edges\n",
    "# nx.draw_networkx_nodes(G, fixed_positions, node_color='skyblue', node_size=1500)\n",
    "# nx.draw_networkx_edges(G, fixed_positions, edgelist=edges, arrowstyle='->', arrowsize=20)\n",
    "# \n",
    "# # Draw node labels next to the nodes\n",
    "# for node, (x, y) in fixed_positions.items():\n",
    "#     label = node_labels[node]\n",
    "#     plt.text(x + 0.1, y, label, fontsize=10, fontweight='bold', ha='left', va='center')\n",
    "# \n",
    "# # Draw edge labels (optional)\n",
    "# edge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\n",
    "# nx.draw_networkx_edge_labels(G, fixed_positions, edge_labels=edge_labels)\n",
    "# \n",
    "# # Show the plot\n",
    "# plt.title(\"Supply Chain Network with Labels Next to Nodes\")\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84fd7abc9915c87e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de9e6789c521f644",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
