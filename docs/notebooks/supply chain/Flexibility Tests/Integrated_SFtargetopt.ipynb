{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.689416Z",
     "start_time": "2025-07-11T03:05:10.686626Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from ppopt.mplp_program import MPLP_Program\n",
    "from ppopt.mpmodel import MPModeler\n",
    "from ppopt.mp_solvers.solve_mpqp import solve_mpqp, mpqp_algorithm\n",
    "from numpy.polynomial.legendre import leggauss\n",
    "from scipy.optimize import linprog\n",
    "from typing import Union\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import time\n",
    "import sympy as sp\n",
    "from typing import Union, List\n",
    "import pickle\n",
    "# from sympy import symbols, expand, lambdify, Expr, simplify, pprint, Rel\n",
    "import math\n",
    "from pyomo.environ import *\n",
    "import pyomo.environ as pyo\n",
    "from typing import List\n",
    "import itertools\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "def gauss_legendre_between_bounds(expr_coeffs: np.ndarray, n_gl: int, max_idx: int = 0, min_idx: int = 1):\n",
    "    \"\"\"\n",
    "    Generate n Gauss–Legendre quadrature points and weights between min and max bounds\n",
    "    defined by two linear expressions.\n",
    "\n",
    "    Parameters:\n",
    "        expr_coeffs (np.ndarray): 2xD array. Row 0 = max point co`efficients, Row 1 = min.\n",
    "        n (int): Number of quadrature points.\n",
    "\n",
    "    Returns:\n",
    "        points (np.ndarray): (n, D) array of quadrature points.\n",
    "        weights (np.ndarray): (n,) array of weights.\n",
    "    \"\"\"\n",
    "    if expr_coeffs.shape[0] != 2:\n",
    "        raise ValueError(\"expr_coeffs must have two rows\")\n",
    "\n",
    "    max_coeffs = expr_coeffs[max_idx]\n",
    "    min_coeffs = expr_coeffs[min_idx]\n",
    "\n",
    "    # Get Gauss–Legendre points and weights on [-1, 1]\n",
    "    nodes, weights = leggauss(n_gl)\n",
    "    weights = weights.reshape(-1,1)\n",
    "    \n",
    "    # Affine transformation to domain [min_coeffs, max_coeffs]\n",
    "    points = 0.5 * (np.outer((nodes + 1), max_coeffs) + np.outer((1 - nodes), min_coeffs))\n",
    "\n",
    "    # Adjust weights to match new domain\n",
    "    weights = 0.5 * weights@(max_coeffs - min_coeffs).reshape(1,-1)\n",
    "\n",
    "    return points, weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.720139Z",
     "start_time": "2025-07-11T03:05:10.717041Z"
    }
   },
   "id": "998918dd573f3459",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "def get_quadrature_points(solution, nq: int, t_vector: np.ndarray):\n",
    "    # Augment t_vector once\n",
    "    t_vector_aug = np.append(t_vector, 1).reshape(-1, 1)\n",
    "\n",
    "    if isinstance(solution, list):\n",
    "        qpoints, qweights = np.polynomial.legendre.leggauss(nq)\n",
    "        min, max = solution[0], solution[1]\n",
    "        qps_mapped = 0.5*(max*(1+qpoints) + min*(1-qpoints))\n",
    "        qws_mapped = 0.5*(max-min)*qweights\n",
    "        # print(max, min, qps_mapped, qws_mapped)\n",
    "        return max, min, qps_mapped, qws_mapped\n",
    "\n",
    "    for region in solution.critical_regions:\n",
    "        if region.is_inside(t_vector):\n",
    "            coeffs = np.concatenate([region.A, region.b], axis=1)[:2, :]\n",
    "            qpoints, qweights = gauss_legendre_between_bounds(expr_coeffs=coeffs, n_gl=nq)\n",
    "            return coeffs[0] @ t_vector_aug, coeffs[1] @ t_vector_aug, qpoints @ t_vector_aug, qweights @ t_vector_aug\n",
    "\n",
    "    # print(f't_vector: {t_vector}')\n",
    "    # print(f'solution:{solution}')\n",
    "    raise ValueError(\"No region found that contains the given t_vector.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.740864Z",
     "start_time": "2025-07-11T03:05:10.737685Z"
    }
   },
   "id": "f107e25ebb9ca6af",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "def mpformulate_theta_bounds(flex_sol, num_theta:int, theta_bounds:list, num_design:int=0, design_bounds:list=None, psi_idx:int=0, theta_m:int=0):\n",
    "    A0, b0, F0 = np.empty((len(flex_sol), num_theta)), np.empty((len(flex_sol), 1)), np.empty((len(flex_sol), num_design))\n",
    "    num_cr = len(flex_sol.critical_regions)\n",
    "    for i, region in enumerate(flex_sol.critical_regions):\n",
    "        A0[i] = region.A[psi_idx,:num_theta]\n",
    "        b0[i] = -region.b[psi_idx]\n",
    "        F0[i] = -region.A[psi_idx, num_theta:num_theta+num_design]\n",
    "    # print(f'num_cr:{num_cr}')\n",
    "    # print(f'num_theta:{num_theta}')\n",
    "    # print(f'num_design:{num_design}')\n",
    "    # print(f\"A0: {A0}\")\n",
    "    # print(f\"b0: {b0}\")\n",
    "    # print(f\"F0: {F0}\")\n",
    "    \n",
    "    c = np.hstack([np.array([-1, 1]).reshape(1, -1), np.zeros((1, 2 * (num_theta - 1 - theta_m)))]).reshape(-1,1)\n",
    "    # print(f'c:{c}')\n",
    "    # print(f'c.shape: {c.shape}')\n",
    "    \n",
    "    row1_block = np.hstack([block for i in range(theta_m, num_theta) for block in (A0[:, [i]], np.zeros((num_cr, 1)))])\n",
    "    row2_block = np.hstack([block for i in range(theta_m, num_theta) for block in (np.zeros((num_cr, 1)), A0[:, [i]])])\n",
    "    bound_row = np.hstack([np.array([-1, 1]).reshape(1, -1), np.zeros((1, 2 * (num_theta - 1 - theta_m)))])\n",
    "    A = np.vstack([row1_block, row2_block, bound_row, -np.eye(2*(num_theta-theta_m)), np.eye(2*(num_theta-theta_m))])\n",
    "    # print(f'A: {A}')\n",
    "    # print(f'A.shape: {A.shape}')\n",
    "    \n",
    "    x_lb = np.array([val for i in range(theta_m, len(theta_bounds)) for val in [theta_bounds[i][0]] * 2])\n",
    "    x_ub = np.array([val for i in range(theta_m, len(theta_bounds)) for val in [theta_bounds[i][1]] * 2])\n",
    "    b = np.vstack([b0, b0, np.zeros((1,1)), -x_lb.reshape(-1,1), x_ub.reshape(-1,1)])\n",
    "    # print(f'b: {b}')\n",
    "    # print(f'b.shape: {b.shape}')\n",
    "    \n",
    "    if F0.size==0 and theta_m==0:\n",
    "        # print('here')\n",
    "        return A, b, c, np.array([]), np.array([]), np.array([]), np.array([]) \n",
    "    \n",
    "    F = np.vstack([F0, F0, np.zeros((1,num_design)), np.zeros((4*(num_theta-theta_m), num_design))]) if num_design>0 else np.vstack([F0, F0])\n",
    "    # print(f'F:{F}')\n",
    "    # print(f'F.shape: {F.shape}')\n",
    "    if theta_m > 0:\n",
    "        F_lltheta = np.hstack([A0[:, [i]] for i in range(theta_m)])\n",
    "        # print(f'F_lltheta: {F_lltheta}')\n",
    "        # print(f'F_lltheta.shape: {F_lltheta.shape}')\n",
    "        F = np.hstack([np.vstack([-F_lltheta, -F_lltheta, np.zeros((1,len(range(theta_m)))), np.zeros((4*(num_theta-theta_m), theta_m))]), F]) if F.size > 0 else np.vstack([-F_lltheta, -F_lltheta, np.zeros((1,len(range(theta_m)))), np.zeros((4*(num_theta-theta_m), theta_m))])\n",
    "    # print(f'F:{F}')\n",
    "    # print(f'F.shape: {F.shape}')\n",
    "    \n",
    "    H = np.zeros((2*(num_theta-theta_m), theta_m+num_design))\n",
    "    # print(f'H:{H}')\n",
    "    # print(f'H.shape: {H.shape}')\n",
    "    \n",
    "    A_t = np.vstack([-np.eye(theta_m+num_design), np.eye(theta_m+num_design)])\n",
    "    # print(f'A_t:{A_t}')\n",
    "    # print(f'A_t.shape: {A_t.shape}')\n",
    "    \n",
    "    theta_lb = np.array([-theta_bounds[i][0] for i in range(theta_m)] + ([-j[0] for j in design_bounds] if isinstance(design_bounds, list) \n",
    "                                                                        else [])).reshape(-1, 1)\n",
    "    theta_ub = np.array([theta_bounds[i][1] for i in range(theta_m)] + ([j[1] for j in design_bounds] if isinstance(design_bounds, list) \n",
    "                                                                        else [])).reshape(-1, 1)\n",
    "    \n",
    "    b_t = np.vstack([theta_lb, theta_ub])\n",
    "    # print(f'b_t:{b_t}')\n",
    "    # print(f'b_t.shape: {b_t.shape}')\n",
    "    \n",
    "    return A, b, c, H, A_t, b_t, F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.756410Z",
     "start_time": "2025-07-11T03:05:10.748487Z"
    }
   },
   "id": "984245cc2d537047",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "def get_theta_bounds(flex_sol, numt, tbounds, numd:int=0, dbounds:list=None):\n",
    "    \n",
    "    theta_bound_dict = defaultdict(dict)\n",
    "    prob_dict = defaultdict(dict)\n",
    "    for i in range(numt):\n",
    "        A, b, c, H, A_t, b_t, F = mpformulate_theta_bounds(flex_sol=flex_sol, num_theta=numt ,num_design=numd, theta_bounds=tbounds, design_bounds=dbounds, theta_m=i)\n",
    "        if F.size != 0:\n",
    "            prob = MPLP_Program(A=A, b=b, c=c, H=H, A_t=A_t, b_t=b_t, F=F)\n",
    "            prob.process_constraints()\n",
    "            solution = solve_mpqp(problem=prob, algorithm=mpqp_algorithm.geometric)\n",
    "            prob_dict[f't{i}'] = prob\n",
    "            theta_bound_dict[f't{i}'] = solution\n",
    "        else:\n",
    "            linsol = linprog(c=c, A_ub=A, b_ub=b)\n",
    "            prob_dict[f't{i}'] = linsol\n",
    "            theta_bound_dict[f't{i}'] = [linsol.x[1], linsol.x[0]]\n",
    "            # if linsol.success:\n",
    "                # print(\"Optimal value:\", linsol.fun)\n",
    "                # print(\"Optimal x:\", linsol.x)\n",
    "        print(f'Finished solving for theta{i+1}')\n",
    "    probs = [p for key, p in prob_dict.items()]\n",
    "    sols = [sol for key, sol in theta_bound_dict.items()]\n",
    "    \n",
    "    return probs, sols\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.760411Z",
     "start_time": "2025-07-11T03:05:10.757409Z"
    }
   },
   "id": "9acee7702a7b223",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_stocflexibility(sols, nq: Union[int, list], joint_func, d_vector: np.ndarray = None):\n",
    "    \n",
    "    # Validate nq if it's a list\n",
    "    if isinstance(nq, list):\n",
    "        if len(nq) != len(sols):\n",
    "            raise ValueError(\"If nq is a list, it must have the same length as sols\")\n",
    "\n",
    "    def recurse(level: int, theta_prev: list, weight_prev: float) -> float:\n",
    "        \"\"\"\n",
    "        Recursive inner function to compute nested quadrature.\n",
    "        \"\"\"\n",
    "        # print(f'level:{level}')\n",
    "        if level == len(sols):\n",
    "            return weight_prev * joint_func(theta_prev)\n",
    "\n",
    "        # Use nq[level] if nq is a list, otherwise use scalar nq\n",
    "        nql = nq[level] if isinstance(nq, list) else nq\n",
    "\n",
    "        t_vector = np.block([np.array(theta_prev), d_vector]) if isinstance(d_vector, np.ndarray) else np.array(theta_prev)\n",
    "        # print(f't_vector:{t_vector}')\n",
    "        # print(f'probs[{level}].A:{probs[level].A}')\n",
    "        _, _, t_points, t_weights = get_quadrature_points(solution=sols[level], nq=nql, t_vector=t_vector)\n",
    "\n",
    "        t_points = t_points.flatten()\n",
    "        t_weights = t_weights.flatten()\n",
    "        # print('t_points:', t_points)\n",
    "        # print(f'theta_prev: {theta_prev}')\n",
    "        return sum(recurse(level + 1, theta_prev + [v], weight_prev * w) for v, w in zip(t_points, t_weights))\n",
    "    s = time.time()\n",
    "    stflex =  recurse(level=0, theta_prev=[], weight_prev=1.0)\n",
    "    e = time.time()\n",
    "    print(f'Elapsed time for calculating sf index: {e- s}')\n",
    "    \n",
    "    return stflex\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.764320Z",
     "start_time": "2025-07-11T03:05:10.761116Z"
    }
   },
   "id": "9316eda3a0493d64",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Bansal (2000) Illustrative Example\n",
    "t_bounds=[(0,4),(0,4)]\n",
    "d_bounds=[(0,5), (0,5)]\n",
    "nt = len(t_bounds)\n",
    "nd = len(d_bounds)\n",
    "\n",
    "m = MPModeler()\n",
    "\n",
    "u = m.add_var(name='u')\n",
    "x = m.add_var(name='x')\n",
    "z = m.add_var(name='z')\n",
    "\n",
    "t1 = m.add_param(name='t1')\n",
    "t2 = m.add_param(name='t2')\n",
    "d1 = m.add_param(name='d1')\n",
    "d2 = m.add_param(name='d2')\n",
    "m.add_constr(2*x - 3*z + t1 - d2 == 0)\n",
    "m.add_constr(x - z/2 -t1/2 +t2/2 +d1 -7*d2/2 <= u)\n",
    "m.add_constr(-2*x +2*z -4*t1/3 -t2 +2*d2 +1/3<= u)\n",
    "m.add_constr(-x + 5*z/2 +t1/2 -t2 -d1 +d2/2 -1 <= u)\n",
    "m.add_constr(-50 <= x)\n",
    "m.add_constr(-50 <= z)\n",
    "m.add_constr(t_bounds[0][0] <= t1)\n",
    "m.add_constr(t_bounds[1][0] <= t2)\n",
    "m.add_constr(d_bounds[0][0] <= d1)\n",
    "m.add_constr(d_bounds[1][0] <= d2)\n",
    "m.add_constr(t1 <= t_bounds[0][1])\n",
    "m.add_constr(t2 <= t_bounds[1][1])\n",
    "m.add_constr(d1 <= d_bounds[0][1])\n",
    "m.add_constr(d2 <= d_bounds[1][1])\n",
    "m.set_objective(u)\n",
    "prob = m.formulate_problem()\n",
    "prob.process_constraints()\n",
    "solution_flexibility = solve_mpqp(problem=prob, algorithm=mpqp_algorithm.geometric)\n",
    "\n",
    "start_time = time.time()\n",
    "prob_list, sol_list = get_theta_bounds(flex_sol=solution_flexibility, numt=nt, numd=nd, tbounds=t_bounds, dbounds=d_bounds)\n",
    "end_time = time.time()\n",
    "print(f'Elapsed time for solving mp problems: {end_time-start_time}')\n",
    "\n",
    "def joint_pdf(theta:list):\n",
    "    return (2/np.pi)*np.exp(-2*((theta[0]-2)**2 + (theta[1]-2)**2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.829949Z",
     "start_time": "2025-07-11T03:05:10.765648Z"
    }
   },
   "id": "c692821ee2c493b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a found active set [0, 2, 3]\n",
      "Using a found active set [6, 9, 11, 12]\n",
      "Finished solving for theta1\n",
      "Using a found active set [6, 7]\n",
      "Finished solving for theta2\n",
      "Elapsed time for solving mp problems: 0.04101395606994629\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# d_vector = np.array([5, 1.159054910657785])\n",
    "# nq = 5\n",
    "# sf_idx = calculate_stocflexibility(sols=sol_list, nq=nq, joint_func=joint_pdf, d_vector=d_vector)\n",
    "# print(f'Stochastic Flexibility Index: {sf_idx:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.832607Z",
     "start_time": "2025-07-11T03:05:10.830770Z"
    }
   },
   "id": "5fc17883ef6ef2",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finished Calculation of stochastic flexibility index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32535d75f6e97dd8"
  },
  {
   "cell_type": "code",
   "source": [
    "def get_bounds_regions(sols:List, min_idx:int=1, max_idx:int=0):\n",
    "    theta_bounds_list = list()\n",
    "    theta_regions_list = list()\n",
    "    \n",
    "    for theta_sol in sols:\n",
    "        min_max_list = list()\n",
    "        region_list = list()\n",
    "        for cr in theta_sol.critical_regions:\n",
    "            Ab = np.concatenate([cr.A, cr.b], axis=1)[:2]\n",
    "            min_max_list.append([Ab[min_idx].tolist(), Ab[max_idx].tolist()])\n",
    "    \n",
    "            Ef = np.concatenate([cr.E, -cr.f], axis=1)\n",
    "            region_list.append([row.tolist() for row in Ef])\n",
    "    \n",
    "        theta_bounds_list.append(np.array(min_max_list))\n",
    "        theta_regions_list.append(np.array(region_list, dtype=object))  \n",
    "    \n",
    "    return theta_bounds_list, theta_regions_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.836278Z",
     "start_time": "2025-07-11T03:05:10.833551Z"
    }
   },
   "id": "43cb194f3497f77e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.840155Z",
     "start_time": "2025-07-11T03:05:10.837751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_region_combos(region_sizes, n_gl):\n",
    "    \"\"\"Generate region index combinations based on critical region structure.\"\"\"\n",
    "    n_theta = len(region_sizes)\n",
    "    region_combo_shape = []\n",
    "    for k in range(n_theta):\n",
    "        n_paths = int(np.prod(n_gl[:k])) if k > 0 else 1\n",
    "        region_combo_shape.extend([range(region_sizes[k])] * n_paths)\n",
    "    return list(itertools.product(*region_combo_shape))"
   ],
   "id": "4c7165f2dc1ce10f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.843623Z",
     "start_time": "2025-07-11T03:05:10.840952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def affine_expr(coeffs, symbols):\n",
    "    return sum(c * s for c, s in zip(coeffs[:-1], symbols)) + coeffs[-1]"
   ],
   "id": "92b59b1b10146fc",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.846090Z",
     "start_time": "2025-07-11T03:05:10.844455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalized_lhs(ineq):\n",
    "    return ineq.lhs.expand()"
   ],
   "id": "b9e0dfb36a3e7ea4",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.852818Z",
     "start_time": "2025-07-11T03:05:10.847013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_sf_exprs_regions(\n",
    "    theta_bounds_list,\n",
    "    theta_regions_list,\n",
    "    joint_pdf_expr,\n",
    "    d_syms,\n",
    "    n_gl_list,\n",
    "    theta_syms\n",
    "):\n",
    "    n_theta = len(theta_syms)\n",
    "    quad_data = [np.polynomial.legendre.leggauss(n) for n in n_gl_list]\n",
    "    region_sizes = [bounds.shape[0] for bounds in theta_bounds_list]\n",
    "    region_combos = generate_region_combos(region_sizes, n_gl_list)\n",
    "\n",
    "    sf_exprs = []\n",
    "    sf_regions = []\n",
    "\n",
    "    for region_combo in region_combos:\n",
    "        combo_ptr = 0\n",
    "        # Initialize integration paths: (theta_vals, weight, scale, constraints)\n",
    "        paths = [([], 1, 1, [])]\n",
    "\n",
    "        for level in range(n_theta):\n",
    "            xi, wi = quad_data[level]\n",
    "            new_paths = []\n",
    "\n",
    "            for theta_vals, weight, scale, constraints in paths:\n",
    "                region_idx = region_combo[combo_ptr]\n",
    "                combo_ptr += 1\n",
    "\n",
    "                bound_inputs = theta_vals + list(d_syms)\n",
    "                bounds = theta_bounds_list[level][region_idx]\n",
    "                t_min = affine_expr(bounds[0], bound_inputs)\n",
    "                t_max = affine_expr(bounds[1], bound_inputs)\n",
    "\n",
    "                # Get level-specific region constraints\n",
    "                rows = theta_regions_list[level][region_idx]\n",
    "                level_constraints = []\n",
    "                for row in rows:\n",
    "                    t_coeffs = row[:level]\n",
    "                    d_coeffs = row[level:-1]\n",
    "                    const = row[-1]\n",
    "                    lhs = sum(c * theta_vals[i] for i, c in enumerate(t_coeffs)) + \\\n",
    "                          sum(c * d for c, d in zip(d_coeffs, d_syms)) + const\n",
    "                    # level_constraints.append(sp.simplify(lhs <= 0))\n",
    "                    level_constraints.append(lhs <= 0)\n",
    "\n",
    "                new_constraints = constraints + level_constraints\n",
    "\n",
    "                # Quadrature expansion for this level\n",
    "                for q in range(len(xi)):\n",
    "                    t = 0.5 * (t_max - t_min) * xi[q] + 0.5 * (t_max + t_min)\n",
    "                    # new_theta_vals = theta_vals + [sp.simplify(t)]\n",
    "                    new_theta_vals = theta_vals + [t]\n",
    "                    new_weight = weight * wi[q]\n",
    "                    new_scale = scale * 0.5 * (t_max - t_min)\n",
    "                    new_paths.append((new_theta_vals, new_weight, new_scale, new_constraints))\n",
    "\n",
    "            paths = new_paths\n",
    "\n",
    "        # Final integration and region collection\n",
    "        sf_sum = 0\n",
    "        all_constraints = []\n",
    "        for theta_vals, weight, scale, constraints in paths:\n",
    "            theta_subs = {sym: val for sym, val in zip(theta_syms, theta_vals)}\n",
    "            pdf_val = joint_pdf_expr.subs(theta_subs)\n",
    "            sf_sum += weight * scale * pdf_val\n",
    "            all_constraints.extend(constraints)\n",
    "\n",
    "        # Deduplicate constraints symbolically\n",
    "        unique_constraints = []\n",
    "        for c in all_constraints:\n",
    "            if not any(normalized_lhs(c) == normalized_lhs(u) and type(c) == type(u) for u in unique_constraints):\n",
    "                unique_constraints.append(c)  # keep original form for clarity\n",
    "            # if not any(is_same_inequality(c, u) for u in unique_constraints):\n",
    "            #     unique_constraints.append(sp.simplify(c))\n",
    "\n",
    "        sf_exprs.append(sf_sum)\n",
    "        # sf_regions.append(sorted(all_constraints, key=str))\n",
    "        # sf_exprs.append(sp.simplify(sf_sum))\n",
    "        sf_regions.append(sorted(unique_constraints, key=str))\n",
    "\n",
    "    return sf_exprs, sf_regions"
   ],
   "id": "4dfb2d1513282b75",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.861066Z",
     "start_time": "2025-07-11T03:05:10.853726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_constraints_from_expressions(\n",
    "    expr_list: List[sp.Expr],\n",
    "    region_list: List[List[sp.Expr]],\n",
    "    instance: ConcreteModel,\n",
    "    bounds_dict:dict,\n",
    "    target: float = 1.0,\n",
    "    big_m: float = 1e3\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds constraint expressions to a Pyomo model using Big-M logic. For each expression in expr_list,\n",
    "    the constraint is enforced only if the design variables lie in the corresponding critical region\n",
    "    defined in region_list.\n",
    "\n",
    "    Args:\n",
    "        expr_list: List of SymPy expressions representing SF constraints.\n",
    "        region_list: List of lists of SymPy inequality expressions defining valid regions.\n",
    "        instance: Pyomo model (ConcreteModel).\n",
    "        target: The minimum acceptable value for each SF expression.\n",
    "        big_m: Big-M constant for constraint activation.\n",
    "    \"\"\"\n",
    "    assert len(expr_list) == len(region_list), \"Each expression must have a corresponding region definition.\"\n",
    "\n",
    "    if not hasattr(instance, \"generated_constraints\"):\n",
    "        instance.generated_constraints = ConstraintList()\n",
    "    if not hasattr(instance, \"region_constraints\"):\n",
    "        instance.region_constraints = ConstraintList()\n",
    "    if not hasattr(instance, \"region_binaries\"):\n",
    "        instance.region_binaries = Var(range(len(expr_list)), within=Binary)\n",
    "\n",
    "    sf_expr_pyomo_list = list()\n",
    "\n",
    "    for i, (sf_expr, region_exprs) in enumerate(zip(expr_list, region_list)):\n",
    "        # Get all symbols in SF expression and region inequalities\n",
    "        all_syms = sf_expr.free_symbols.union(*[reg.free_symbols for reg in region_exprs])\n",
    "        all_syms = list(all_syms)\n",
    "\n",
    "        # Ensure all symbols are added to the Pyomo model\n",
    "        pyomo_vars = []\n",
    "        for sym in all_syms:\n",
    "            var_name = str(sym)\n",
    "            if not hasattr(instance, var_name):\n",
    "                setattr(instance, var_name, Var(bounds=bounds_dict[var_name]))\n",
    "            pyomo_vars.append(getattr(instance, var_name))\n",
    "\n",
    "        # Create a dict for substitution and lambdify\n",
    "        sym_to_pyomo = {str(sym): getattr(instance, str(sym)) for sym in all_syms}\n",
    "        lambdify_vars = list(sym_to_pyomo.keys())\n",
    "        lambdify_vals = [sym_to_pyomo[s] for s in lambdify_vars]\n",
    "\n",
    "        # Lambdify SF expression\n",
    "        sf_func = sp.lambdify(lambdify_vars, sf_expr, modules=[{'exp': pyo.exp, 'pi': math.pi}, 'sympy'])\n",
    "        sf_pyomo = sf_func(*lambdify_vals)\n",
    "        sf_expr_pyomo_list.append(sf_pyomo)\n",
    "\n",
    "        # Constraint: enforce SF ≥ target only when region binary = 1\n",
    "        instance.generated_constraints.add(\n",
    "            sf_pyomo >= target - big_m * (1 - instance.region_binaries[i])\n",
    "        )\n",
    "\n",
    "        # Region constraints: region_expr <= 0 + M*(1 - delta_i)\n",
    "        for reg_expr in region_exprs:\n",
    "            if not isinstance(reg_expr, sp.Rel):\n",
    "                raise ValueError(f\"Invalid region expression: {reg_expr} is not a relational (inequality) expression.\")\n",
    "\n",
    "            reg_func_lhs = sp.lambdify(lambdify_vars, reg_expr.lhs, modules='sympy')\n",
    "            reg_func_rhs = sp.lambdify(lambdify_vars, reg_expr.rhs, modules='sympy')\n",
    "            lhs_pyomo = reg_func_lhs(*lambdify_vals)\n",
    "            rhs_pyomo = reg_func_rhs(*lambdify_vals)\n",
    "\n",
    "            delta = instance.region_binaries[i]\n",
    "            M_term = big_m * (1 - delta)\n",
    "\n",
    "            if reg_expr.rel_op == '<=':\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo + M_term)\n",
    "            elif reg_expr.rel_op == '<':\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo - 1e-6 + M_term)\n",
    "            elif reg_expr.rel_op == '>=':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo - M_term)\n",
    "            elif reg_expr.rel_op == '>':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo + 1e-6 - M_term)\n",
    "            elif reg_expr.rel_op == '==':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo - M_term)\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo + M_term)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported relational operator: {reg_expr.rel_op}\")\n",
    "\n",
    "    # Optional: Only one region can be active\n",
    "    instance.region_exclusivity = Constraint(expr=sum(instance.region_binaries[i] for i in range(len(expr_list))) == 1)\n",
    "    if not hasattr(instance, 'sf'):\n",
    "        instance.sf = Var(within=NonNegativeReals)\n",
    "\n",
    "    if not hasattr(instance, 'sf_con'):\n",
    "        instance.sf_con = Constraint(expr = instance.sf == sum(sf_expr_pyomo_list[i] * instance.region_binaries[i] for i in range(len(expr_list))))"
   ],
   "id": "5a46ed9ebf1f303f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": "t_bounds_list, t_regions_list = get_bounds_regions(sols=sol_list)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.863929Z",
     "start_time": "2025-07-11T03:05:10.861788Z"
    }
   },
   "id": "3952fe2d38a578e3",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.868357Z",
     "start_time": "2025-07-11T03:05:10.864621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Define Symbols ---\n",
    "theta_syms = sp.symbols(f'theta_0:{nt}')\n",
    "d_syms = sp.symbols(f'd0:{nd}')\n",
    "theta_0, theta_1 = theta_syms\n",
    "d1, d2 = d_syms\n",
    "\n",
    "n_gl_list = [3,3]\n",
    "\n",
    "# Bounds arrays\n",
    "theta1_bounds_array = np.array([\n",
    "    [[0.0, 0.0, 0.0], [0.0, 0.0, 4.0]],  # d0 ± 10\n",
    "    [[0.75, -1.5, -1.25], [0.0, 0.0, 4.0]]  # d1 ± 5\n",
    "])\n",
    "\n",
    "theta2_bounds_array = np.array([\n",
    "    [[-8/3, 2.0, -4.0, 2/3], [0.0, 0.0, 0.0, 4.0]],\n",
    "    [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 4.0]],\n",
    "    [[1/3, -0.5, 0.5, -1/3], [0.0, 0.0, 0.0, 4.0]]\n",
    "])\n",
    "\n",
    "# Critical regions (CRs)\n",
    "# theta1_critical_regions: constraints in terms of d (shape: n_regions × n_ineqs × (m+1))\n",
    "theta1_critical_regions = np.array([\n",
    "    [[1, -2, -5/3]],\n",
    "    [[-1, 2, 5/3]]\n",
    "], dtype=object)\n",
    "\n",
    "# theta2_critical_regions: constraints in terms of [theta1, d0, d1, const]\n",
    "theta2_critical_regions = np.array([\n",
    "    [[-8/3, 2, -4, -10/3], [8/3, -2, 4, -2/3]],\n",
    "    [[8/3, -4.0, 4.0, -8/3], [-8/3, 2, -4, 2/3]],\n",
    "    [[-8/3, 4, -4, 8/3]]\n",
    "], dtype=object)\n",
    "\n",
    "# --- Setup lists ---\n",
    "theta_bounds_list = [theta1_bounds_array, theta2_bounds_array]\n",
    "theta_regions_list = [theta1_critical_regions, theta2_critical_regions]\n",
    "\n",
    "joint_pdf_expr = (2/sp.pi) * sp.exp(-2 * ((theta_0 - 2) ** 2 + (theta_1 - 2) ** 2))"
   ],
   "id": "d625b5e86163b974",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.872445Z",
     "start_time": "2025-07-11T03:05:10.869181Z"
    }
   },
   "cell_type": "code",
   "source": "theta_regions_list[0]",
   "id": "3931d5c65b443cc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, -2, -1.6666666666666667]],\n",
       "\n",
       "       [[-1, 2, 1.6666666666666667]]], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.876672Z",
     "start_time": "2025-07-11T03:05:10.874569Z"
    }
   },
   "cell_type": "code",
   "source": "t_regions_list[0]",
   "id": "4cafb155b737654",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([[0.44721359549995826, -0.8944271909999157, -0.7453559924999327], [-1.0, -0.0, -0.0], [-0.0, -1.0, -0.0], [1.0, 0.0, -5.0], [0.0, 1.0, -5.0]]),\n",
       "       list([[-0.4472135954999582, 0.8944271909999156, 0.7453559924999327], [-0.0, -1.0, -0.0], [1.0, 0.0, -5.0]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "sf_exprs, sf_regions = compute_sf_exprs_regions(theta_bounds_list=t_bounds_list, theta_regions_list=t_regions_list,\n",
    "                                                                              joint_pdf_expr=joint_pdf_expr, d_syms=[d1, d2], n_gl_list=n_gl_list,theta_syms=theta_syms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.965533Z",
     "start_time": "2025-07-11T03:05:10.877268Z"
    }
   },
   "id": "b34faf27411fcf53",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BooleanTrue' object has no attribute 'lhs'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sf_exprs, sf_regions \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_sf_exprs_regions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtheta_bounds_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_bounds_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtheta_regions_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt_regions_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                                                                              \u001B[49m\u001B[43mjoint_pdf_expr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjoint_pdf_expr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_syms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43md1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_gl_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_gl_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtheta_syms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtheta_syms\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 72\u001B[0m, in \u001B[0;36mcompute_sf_exprs_regions\u001B[0;34m(theta_bounds_list, theta_regions_list, joint_pdf_expr, d_syms, n_gl_list, theta_syms)\u001B[0m\n\u001B[1;32m     70\u001B[0m unique_constraints \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m all_constraints:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43many\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnormalized_lhs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnormalized_lhs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mu\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43munique_constraints\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     73\u001B[0m         unique_constraints\u001B[38;5;241m.\u001B[39mappend(c)  \u001B[38;5;66;03m# keep original form for clarity\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;66;03m# if not any(is_same_inequality(c, u) for u in unique_constraints):\u001B[39;00m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;66;03m#     unique_constraints.append(sp.simplify(c))\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[32], line 72\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     70\u001B[0m unique_constraints \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m all_constraints:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[43mnormalized_lhs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m==\u001B[39m normalized_lhs(u) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(c) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mtype\u001B[39m(u) \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m unique_constraints):\n\u001B[1;32m     73\u001B[0m         unique_constraints\u001B[38;5;241m.\u001B[39mappend(c)  \u001B[38;5;66;03m# keep original form for clarity\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;66;03m# if not any(is_same_inequality(c, u) for u in unique_constraints):\u001B[39;00m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;66;03m#     unique_constraints.append(sp.simplify(c))\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m, in \u001B[0;36mnormalized_lhs\u001B[0;34m(ineq)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mnormalized_lhs\u001B[39m(ineq):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mineq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlhs\u001B[49m\u001B[38;5;241m.\u001B[39mexpand()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'BooleanTrue' object has no attribute 'lhs'"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.966487Z",
     "start_time": "2025-07-11T03:05:10.966419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Number of SF expressions: {len(sf_exprs)}')\n",
    "print(f'Number of critical regions: {len(sf_regions)}')"
   ],
   "id": "d4d6ad3f0ee05b1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T03:05:10.967104Z",
     "start_time": "2025-07-11T03:05:10.967012Z"
    }
   },
   "cell_type": "code",
   "source": "design_bounds = {f'd{i}':bounds for i, bounds in enumerate(d_bounds)}",
   "id": "f415a2d5a6f8076a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "design_bounds",
   "id": "baa8b62f60764411",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e274de33fcbf2735",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
