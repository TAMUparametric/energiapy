{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.235455Z",
     "start_time": "2025-07-11T13:52:40.217631Z"
    }
   },
   "source": [
    "from ppopt.mplp_program import MPLP_Program\n",
    "from ppopt.mpmodel import MPModeler\n",
    "from ppopt.mp_solvers.solve_mpqp import solve_mpqp, mpqp_algorithm\n",
    "from numpy.polynomial.legendre import leggauss\n",
    "from scipy.optimize import linprog\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import sympy as sp\n",
    "from sympy.logic.boolalg import BooleanTrue, BooleanFalse\n",
    "from typing import Union, List\n",
    "import pickle\n",
    "import math\n",
    "from pyomo.environ import *\n",
    "import pyomo.environ as pyo\n",
    "import itertools\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "source": [
    "def gauss_legendre_between_bounds(expr_coeffs: np.ndarray, n_gl: int, max_idx: int = 0, min_idx: int = 1):\n",
    "    \"\"\"\n",
    "    Generate n Gauss–Legendre quadrature points and weights between min and max bounds\n",
    "    defined by two linear expressions.\n",
    "\n",
    "    Parameters:\n",
    "        expr_coeffs (np.ndarray): 2xD array. Row 0 = max point co`efficients, Row 1 = min.\n",
    "        n (int): Number of quadrature points.\n",
    "\n",
    "    Returns:\n",
    "        points (np.ndarray): (n, D) array of quadrature points.\n",
    "        weights (np.ndarray): (n,) array of weights.\n",
    "    \"\"\"\n",
    "    if expr_coeffs.shape[0] != 2:\n",
    "        raise ValueError(\"expr_coeffs must have two rows\")\n",
    "\n",
    "    max_coeffs = expr_coeffs[max_idx]\n",
    "    min_coeffs = expr_coeffs[min_idx]\n",
    "\n",
    "    # Get Gauss–Legendre points and weights on [-1, 1]\n",
    "    nodes, weights = leggauss(n_gl)\n",
    "    weights = weights.reshape(-1,1)\n",
    "    \n",
    "    # Affine transformation to domain [min_coeffs, max_coeffs]\n",
    "    points = 0.5 * (np.outer((nodes + 1), max_coeffs) + np.outer((1 - nodes), min_coeffs))\n",
    "\n",
    "    # Adjust weights to match new domain\n",
    "    weights = 0.5 * weights@(max_coeffs - min_coeffs).reshape(1,-1)\n",
    "\n",
    "    return points, weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.251393Z",
     "start_time": "2025-07-11T13:52:40.236501Z"
    }
   },
   "id": "998918dd573f3459",
   "outputs": [],
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "source": [
    "def get_quadrature_points(solution, nq: int, t_vector: np.ndarray):\n",
    "    # Augment t_vector once\n",
    "    t_vector_aug = np.append(t_vector, 1).reshape(-1, 1)\n",
    "\n",
    "    if isinstance(solution, list):\n",
    "        qpoints, qweights = np.polynomial.legendre.leggauss(nq)\n",
    "        min, max = solution[0], solution[1]\n",
    "        qps_mapped = 0.5*(max*(1+qpoints) + min*(1-qpoints))\n",
    "        qws_mapped = 0.5*(max-min)*qweights\n",
    "        # print(max, min, qps_mapped, qws_mapped)\n",
    "        return max, min, qps_mapped, qws_mapped\n",
    "\n",
    "    for region in solution.critical_regions:\n",
    "        if region.is_inside(t_vector):\n",
    "            coeffs = np.concatenate([region.A, region.b], axis=1)[:2, :]\n",
    "            qpoints, qweights = gauss_legendre_between_bounds(expr_coeffs=coeffs, n_gl=nq)\n",
    "            return coeffs[0] @ t_vector_aug, coeffs[1] @ t_vector_aug, qpoints @ t_vector_aug, qweights @ t_vector_aug\n",
    "\n",
    "    # print(f't_vector: {t_vector}')\n",
    "    # print(f'solution:{solution}')\n",
    "    raise ValueError(\"No region found that contains the given t_vector.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.267521Z",
     "start_time": "2025-07-11T13:52:40.254988Z"
    }
   },
   "id": "f107e25ebb9ca6af",
   "outputs": [],
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "source": [
    "def mpformulate_theta_bounds(flex_sol, num_theta:int, theta_bounds:list, num_design:int=0, design_bounds:list=None, psi_idx:int=0, theta_m:int=0):\n",
    "    A0, b0, F0 = np.empty((len(flex_sol), num_theta)), np.empty((len(flex_sol), 1)), np.empty((len(flex_sol), num_design))\n",
    "    num_cr = len(flex_sol.critical_regions)\n",
    "    for i, region in enumerate(flex_sol.critical_regions):\n",
    "        A0[i] = region.A[psi_idx,:num_theta]\n",
    "        b0[i] = -region.b[psi_idx]\n",
    "        F0[i] = -region.A[psi_idx, num_theta:num_theta+num_design]\n",
    "    # print(f'num_cr:{num_cr}')\n",
    "    # print(f'num_theta:{num_theta}')\n",
    "    # print(f'num_design:{num_design}')\n",
    "    # print(f\"A0: {A0}\")\n",
    "    # print(f\"b0: {b0}\")\n",
    "    # print(f\"F0: {F0}\")\n",
    "    \n",
    "    c = np.hstack([np.array([-1, 1]).reshape(1, -1), np.zeros((1, 2 * (num_theta - 1 - theta_m)))]).reshape(-1,1)\n",
    "    # print(f'c:{c}')\n",
    "    # print(f'c.shape: {c.shape}')\n",
    "    \n",
    "    row1_block = np.hstack([block for i in range(theta_m, num_theta) for block in (A0[:, [i]], np.zeros((num_cr, 1)))])\n",
    "    row2_block = np.hstack([block for i in range(theta_m, num_theta) for block in (np.zeros((num_cr, 1)), A0[:, [i]])])\n",
    "    bound_row = np.hstack([np.array([-1, 1]).reshape(1, -1), np.zeros((1, 2 * (num_theta - 1 - theta_m)))])\n",
    "    A = np.vstack([row1_block, row2_block, bound_row, -np.eye(2*(num_theta-theta_m)), np.eye(2*(num_theta-theta_m))])\n",
    "    # print(f'A: {A}')\n",
    "    # print(f'A.shape: {A.shape}')\n",
    "    \n",
    "    x_lb = np.array([val for i in range(theta_m, len(theta_bounds)) for val in [theta_bounds[i][0]] * 2])\n",
    "    x_ub = np.array([val for i in range(theta_m, len(theta_bounds)) for val in [theta_bounds[i][1]] * 2])\n",
    "    b = np.vstack([b0, b0, np.zeros((1,1)), -x_lb.reshape(-1,1), x_ub.reshape(-1,1)])\n",
    "    # print(f'b: {b}')\n",
    "    # print(f'b.shape: {b.shape}')\n",
    "    \n",
    "    if F0.size==0 and theta_m==0:\n",
    "        # print('here')\n",
    "        return A, b, c, np.array([]), np.array([]), np.array([]), np.array([]) \n",
    "    \n",
    "    F = np.vstack([F0, F0, np.zeros((1,num_design)), np.zeros((4*(num_theta-theta_m), num_design))]) if num_design>0 else np.vstack([F0, F0])\n",
    "    # print(f'F:{F}')\n",
    "    # print(f'F.shape: {F.shape}')\n",
    "    if theta_m > 0:\n",
    "        F_lltheta = np.hstack([A0[:, [i]] for i in range(theta_m)])\n",
    "        # print(f'F_lltheta: {F_lltheta}')\n",
    "        # print(f'F_lltheta.shape: {F_lltheta.shape}')\n",
    "        F = np.hstack([np.vstack([-F_lltheta, -F_lltheta, np.zeros((1,len(range(theta_m)))), np.zeros((4*(num_theta-theta_m), theta_m))]), F]) if F.size > 0 else np.vstack([-F_lltheta, -F_lltheta, np.zeros((1,len(range(theta_m)))), np.zeros((4*(num_theta-theta_m), theta_m))])\n",
    "    # print(f'F:{F}')\n",
    "    # print(f'F.shape: {F.shape}')\n",
    "    \n",
    "    H = np.zeros((2*(num_theta-theta_m), theta_m+num_design))\n",
    "    # print(f'H:{H}')\n",
    "    # print(f'H.shape: {H.shape}')\n",
    "    \n",
    "    A_t = np.vstack([-np.eye(theta_m+num_design), np.eye(theta_m+num_design)])\n",
    "    # print(f'A_t:{A_t}')\n",
    "    # print(f'A_t.shape: {A_t.shape}')\n",
    "    \n",
    "    theta_lb = np.array([-theta_bounds[i][0] for i in range(theta_m)] + ([-j[0] for j in design_bounds] if isinstance(design_bounds, list) \n",
    "                                                                        else [])).reshape(-1, 1)\n",
    "    theta_ub = np.array([theta_bounds[i][1] for i in range(theta_m)] + ([j[1] for j in design_bounds] if isinstance(design_bounds, list) \n",
    "                                                                        else [])).reshape(-1, 1)\n",
    "    \n",
    "    b_t = np.vstack([theta_lb, theta_ub])\n",
    "    # print(f'b_t:{b_t}')\n",
    "    # print(f'b_t.shape: {b_t.shape}')\n",
    "    \n",
    "    return A, b, c, H, A_t, b_t, F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.283141Z",
     "start_time": "2025-07-11T13:52:40.268580Z"
    }
   },
   "id": "984245cc2d537047",
   "outputs": [],
   "execution_count": 223
  },
  {
   "cell_type": "code",
   "source": [
    "def get_theta_bounds(flex_sol, numt, tbounds, numd:int=0, dbounds:list=None):\n",
    "    \n",
    "    theta_bound_dict = defaultdict(dict)\n",
    "    prob_dict = defaultdict(dict)\n",
    "    for i in range(numt):\n",
    "        A, b, c, H, A_t, b_t, F = mpformulate_theta_bounds(flex_sol=flex_sol, num_theta=numt ,num_design=numd, theta_bounds=tbounds, design_bounds=dbounds, theta_m=i)\n",
    "        if F.size != 0:\n",
    "            prob = MPLP_Program(A=A, b=b, c=c, H=H, A_t=A_t, b_t=b_t, F=F)\n",
    "            prob.process_constraints()\n",
    "            solution = solve_mpqp(problem=prob, algorithm=mpqp_algorithm.geometric)\n",
    "            prob_dict[f't{i}'] = prob\n",
    "            theta_bound_dict[f't{i}'] = solution\n",
    "        else:\n",
    "            linsol = linprog(c=c, A_ub=A, b_ub=b)\n",
    "            prob_dict[f't{i}'] = linsol\n",
    "            theta_bound_dict[f't{i}'] = [linsol.x[1], linsol.x[0]]\n",
    "            # if linsol.success:\n",
    "                # print(\"Optimal value:\", linsol.fun)\n",
    "                # print(\"Optimal x:\", linsol.x)\n",
    "        print(f'Finished solving for theta{i+1}')\n",
    "    probs = [p for key, p in prob_dict.items()]\n",
    "    sols = [sol for key, sol in theta_bound_dict.items()]\n",
    "    \n",
    "    return probs, sols\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.298624Z",
     "start_time": "2025-07-11T13:52:40.284222Z"
    }
   },
   "id": "9acee7702a7b223",
   "outputs": [],
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_stocflexibility(sols, nq: Union[int, list], joint_func, d_vector: np.ndarray = None):\n",
    "    \n",
    "    # Validate nq if it's a list\n",
    "    if isinstance(nq, list):\n",
    "        if len(nq) != len(sols):\n",
    "            raise ValueError(\"If nq is a list, it must have the same length as sols\")\n",
    "\n",
    "    def recurse(level: int, theta_prev: list, weight_prev: float) -> float:\n",
    "        \"\"\"\n",
    "        Recursive inner function to compute nested quadrature.\n",
    "        \"\"\"\n",
    "        # print(f'level:{level}')\n",
    "        if level == len(sols):\n",
    "            return weight_prev * joint_func(theta_prev)\n",
    "\n",
    "        # Use nq[level] if nq is a list, otherwise use scalar nq\n",
    "        nql = nq[level] if isinstance(nq, list) else nq\n",
    "\n",
    "        t_vector = np.block([np.array(theta_prev), d_vector]) if isinstance(d_vector, np.ndarray) else np.array(theta_prev)\n",
    "        # print(f't_vector:{t_vector}')\n",
    "        # print(f'probs[{level}].A:{probs[level].A}')\n",
    "        _, _, t_points, t_weights = get_quadrature_points(solution=sols[level], nq=nql, t_vector=t_vector)\n",
    "\n",
    "        t_points = t_points.flatten()\n",
    "        t_weights = t_weights.flatten()\n",
    "        # print('t_points:', t_points)\n",
    "        # print(f'theta_prev: {theta_prev}')\n",
    "        return sum(recurse(level + 1, theta_prev + [v], weight_prev * w) for v, w in zip(t_points, t_weights))\n",
    "    s = time.time()\n",
    "    stflex =  recurse(level=0, theta_prev=[], weight_prev=1.0)\n",
    "    e = time.time()\n",
    "    print(f'Elapsed time for calculating sf index: {e- s}')\n",
    "    \n",
    "    return stflex\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.314164Z",
     "start_time": "2025-07-11T13:52:40.299994Z"
    }
   },
   "id": "9316eda3a0493d64",
   "outputs": [],
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "source": [
    "# Bansal (2000) Illustrative Example\n",
    "t_bounds=[(0,4),(0,4)]\n",
    "d_bounds=[(0,5), (0,5)]\n",
    "nt = len(t_bounds)\n",
    "nd = len(d_bounds)\n",
    "\n",
    "m = MPModeler()\n",
    "\n",
    "u = m.add_var(name='u')\n",
    "x = m.add_var(name='x')\n",
    "z = m.add_var(name='z')\n",
    "\n",
    "t1 = m.add_param(name='t1')\n",
    "t2 = m.add_param(name='t2')\n",
    "d1 = m.add_param(name='d1')\n",
    "d2 = m.add_param(name='d2')\n",
    "m.add_constr(2*x - 3*z + t1 - d2 == 0)\n",
    "m.add_constr(x - z/2 -t1/2 +t2/2 +d1 -7*d2/2 <= u)\n",
    "m.add_constr(-2*x +2*z -4*t1/3 -t2 +2*d2 +1/3<= u)\n",
    "m.add_constr(-x + 5*z/2 +t1/2 -t2 -d1 +d2/2 -1 <= u)\n",
    "m.add_constr(-50 <= x)\n",
    "m.add_constr(-50 <= z)\n",
    "m.add_constr(t_bounds[0][0] <= t1)\n",
    "m.add_constr(t_bounds[1][0] <= t2)\n",
    "m.add_constr(d_bounds[0][0] <= d1)\n",
    "m.add_constr(d_bounds[1][0] <= d2)\n",
    "m.add_constr(t1 <= t_bounds[0][1])\n",
    "m.add_constr(t2 <= t_bounds[1][1])\n",
    "m.add_constr(d1 <= d_bounds[0][1])\n",
    "m.add_constr(d2 <= d_bounds[1][1])\n",
    "m.set_objective(u)\n",
    "prob = m.formulate_problem()\n",
    "prob.process_constraints()\n",
    "solution_flexibility = solve_mpqp(problem=prob, algorithm=mpqp_algorithm.geometric)\n",
    "\n",
    "start_time = time.time()\n",
    "prob_list, sol_list = get_theta_bounds(flex_sol=solution_flexibility, numt=nt, numd=nd, tbounds=t_bounds, dbounds=d_bounds)\n",
    "end_time = time.time()\n",
    "print(f'Elapsed time for solving mp problems: {end_time-start_time}')\n",
    "\n",
    "def joint_pdf(theta:list):\n",
    "    return (2/np.pi)*np.exp(-2*((theta[0]-2)**2 + (theta[1]-2)**2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:52:40.455023Z",
     "start_time": "2025-07-11T13:52:40.315220Z"
    }
   },
   "id": "c692821ee2c493b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a found active set [0, 2, 3]\n",
      "Using a found active set [6, 9, 11, 12]\n",
      "Finished solving for theta1\n",
      "Using a found active set [6, 7]\n",
      "Finished solving for theta2\n",
      "Elapsed time for solving mp problems: 0.0821237564086914\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "source": [
    "d_vector = np.array([5, 1.2751179])\n",
    "nq = 5\n",
    "sf_idx = calculate_stocflexibility(sols=sol_list, nq=nq, joint_func=joint_pdf, d_vector=d_vector)\n",
    "print(f'Stochastic Flexibility Index: {sf_idx:.4}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:40.728700Z",
     "start_time": "2025-07-11T14:21:40.715540Z"
    }
   },
   "id": "5fc17883ef6ef2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for calculating sf index: 0.0021228790283203125\n",
      "Stochastic Flexibility Index: 0.9\n"
     ]
    }
   ],
   "execution_count": 253
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finished Calculation of stochastic flexibility index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32535d75f6e97dd8"
  },
  {
   "cell_type": "code",
   "source": [
    "# def get_bounds_regions(sols:List, min_idx:int=1, max_idx:int=0):\n",
    "#     theta_bounds_list = list()\n",
    "#     theta_regions_list = list()\n",
    "#     \n",
    "#     for theta_sol in sols:\n",
    "#         min_max_list = list()\n",
    "#         region_list = list()\n",
    "#         for cr in theta_sol.critical_regions:\n",
    "#             Ab = np.concatenate([cr.A, cr.b], axis=1)[:2]\n",
    "#             min_max_list.append([Ab[min_idx].tolist(), Ab[max_idx].tolist()])\n",
    "#     \n",
    "#             Ef = np.concatenate([cr.E, -cr.f], axis=1)\n",
    "#             region_list.extend([row.tolist() for row in Ef])\n",
    "#     \n",
    "#         theta_bounds_list.append(np.array(min_max_list))\n",
    "#         # theta_regions_list.append(np.array(region_list, dtype=object).reshape(-1,1))\n",
    "#         theta_regions_list.append(np.array([np.array(r, dtype=float) for r in region_list], dtype=object))\n",
    "# \n",
    "#     \n",
    "#     return theta_bounds_list, theta_regions_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.633373Z",
     "start_time": "2025-07-11T13:42:18.619512Z"
    }
   },
   "id": "43cb194f3497f77e",
   "outputs": [],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_bounds_regions(sols: List, min_idx: int = 1, max_idx: int = 0):\n",
    "    theta_bounds_list = []\n",
    "    theta_regions_list = []\n",
    "\n",
    "    for theta_sol in sols:\n",
    "        min_max_list = []\n",
    "        region_list = []\n",
    "\n",
    "        for cr in theta_sol.critical_regions:\n",
    "            # Store bounds\n",
    "            Ab = np.concatenate([cr.A, cr.b], axis=1)[:2]\n",
    "            min_max_list.append([Ab[min_idx].tolist(), Ab[max_idx].tolist()])\n",
    "\n",
    "            # Store region constraints\n",
    "            Ef = np.concatenate([cr.E, -cr.f], axis=1)\n",
    "            region_array = np.array([row.tolist() for row in Ef], dtype=float)\n",
    "            region_list.append(region_array)\n",
    "\n",
    "        # Append per-theta data\n",
    "        theta_bounds_list.append(np.array(min_max_list))\n",
    "        theta_regions_list.append(np.array(region_list, dtype=object))  # <-- each region is a 2D array\n",
    "\n",
    "    return theta_bounds_list, theta_regions_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.649504Z",
     "start_time": "2025-07-11T13:42:18.634433Z"
    }
   },
   "id": "125b0de26b2afb2f",
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.665037Z",
     "start_time": "2025-07-11T13:42:18.651545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_region_combos(region_sizes, n_gl):\n",
    "    \"\"\"Generate region index combinations based on critical region structure.\"\"\"\n",
    "    n_theta = len(region_sizes)\n",
    "    region_combo_shape = []\n",
    "    for k in range(n_theta):\n",
    "        n_paths = int(np.prod(n_gl[:k])) if k > 0 else 1\n",
    "        region_combo_shape.extend([range(region_sizes[k])] * n_paths)\n",
    "    return list(itertools.product(*region_combo_shape))"
   ],
   "id": "4c7165f2dc1ce10f",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.681179Z",
     "start_time": "2025-07-11T13:42:18.665634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def affine_expr(coeffs, symbols):\n",
    "    return sum(c * s for c, s in zip(coeffs[:-1], symbols)) + coeffs[-1]"
   ],
   "id": "92b59b1b10146fc",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.697086Z",
     "start_time": "2025-07-11T13:42:18.682241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalized_lhs(ineq):\n",
    "    return ineq.lhs.expand() if hasattr(ineq, 'lhs') else None"
   ],
   "id": "b9e0dfb36a3e7ea4",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.712755Z",
     "start_time": "2025-07-11T13:42:18.698135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_sf_exprs_regions(\n",
    "    theta_bounds_list,\n",
    "    theta_regions_list,\n",
    "    joint_pdf_expr,\n",
    "    d_syms,\n",
    "    n_gl_list,\n",
    "    theta_syms\n",
    "):\n",
    "    n_theta = len(theta_syms)\n",
    "    quad_data = [np.polynomial.legendre.leggauss(n) for n in n_gl_list]\n",
    "    region_sizes = [bounds.shape[0] for bounds in theta_bounds_list]\n",
    "    region_combos = generate_region_combos(region_sizes, n_gl_list)\n",
    "\n",
    "    sf_exprs = []\n",
    "    sf_regions = []\n",
    "\n",
    "    for region_combo in region_combos:\n",
    "        combo_ptr = 0\n",
    "        # Initialize integration paths: (theta_vals, weight, scale, constraints)\n",
    "        paths = [([], 1, 1, [])]\n",
    "\n",
    "        for level in range(n_theta):\n",
    "            xi, wi = quad_data[level]\n",
    "            new_paths = []\n",
    "\n",
    "            for theta_vals, weight, scale, constraints in paths:\n",
    "                region_idx = region_combo[combo_ptr]\n",
    "                combo_ptr += 1\n",
    "\n",
    "                bound_inputs = theta_vals + list(d_syms)\n",
    "                bounds = theta_bounds_list[level][region_idx]\n",
    "                t_min = affine_expr(bounds[0], bound_inputs)\n",
    "                t_max = affine_expr(bounds[1], bound_inputs)\n",
    "\n",
    "                # Get level-specific region constraints\n",
    "                rows = theta_regions_list[level][region_idx]\n",
    "                level_constraints = []\n",
    "                for row in rows:\n",
    "                    t_coeffs = row[:level]\n",
    "                    d_coeffs = row[level:-1]\n",
    "                    const = row[-1]\n",
    "                    lhs = sum(c * theta_vals[i] for i, c in enumerate(t_coeffs)) + \\\n",
    "                          sum(c * d for c, d in zip(d_coeffs, d_syms)) + const\n",
    "                    ineq = lhs <= 0\n",
    "                    # level_constraints.append(sp.simplify(lhs <= 0))\n",
    "                    if not isinstance(ineq, (BooleanTrue, BooleanFalse)):\n",
    "                        level_constraints.append(ineq)\n",
    "\n",
    "                new_constraints = constraints + level_constraints\n",
    "\n",
    "                # Quadrature expansion for this level\n",
    "                for q in range(len(xi)):\n",
    "                    t = 0.5 * (t_max - t_min) * xi[q] + 0.5 * (t_max + t_min)\n",
    "                    # new_theta_vals = theta_vals + [sp.simplify(t)]\n",
    "                    new_theta_vals = theta_vals + [t]\n",
    "                    new_weight = weight * wi[q]\n",
    "                    new_scale = scale * 0.5 * (t_max - t_min)\n",
    "                    new_paths.append((new_theta_vals, new_weight, new_scale, new_constraints))\n",
    "\n",
    "            paths = new_paths\n",
    "\n",
    "        # Final integration and region collection\n",
    "        sf_sum = 0\n",
    "        all_constraints = []\n",
    "        for theta_vals, weight, scale, constraints in paths:\n",
    "            theta_subs = {sym: val for sym, val in zip(theta_syms, theta_vals)}\n",
    "            pdf_val = joint_pdf_expr.subs(theta_subs)\n",
    "            sf_sum += weight * scale * pdf_val\n",
    "            all_constraints.extend(constraints)\n",
    "\n",
    "        # Deduplicate constraints symbolically\n",
    "        unique_constraints = []\n",
    "        for c in all_constraints:\n",
    "            if isinstance(c, (BooleanTrue, BooleanFalse)):\n",
    "                print(f'Skipping trivial constraint: {c}')\n",
    "            if not any(normalized_lhs(c) == normalized_lhs(u) and type(c) == type(u) for u in unique_constraints if normalized_lhs(u) is not None):\n",
    "                unique_constraints.append(c)\n",
    "\n",
    "        sf_exprs.append(sf_sum)\n",
    "        # sf_regions.append(sorted(all_constraints, key=str))\n",
    "        # sf_exprs.append(sp.simplify(sf_sum))\n",
    "        sf_regions.append(sorted(unique_constraints, key=str))\n",
    "\n",
    "    return sf_exprs, sf_regions"
   ],
   "id": "4dfb2d1513282b75",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.728539Z",
     "start_time": "2025-07-11T13:42:18.713826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_constraints_from_expressions(\n",
    "    expr_list: List[sp.Expr],\n",
    "    region_list: List[List[sp.Expr]],\n",
    "    instance: ConcreteModel,\n",
    "    bounds_dict:dict,\n",
    "    target: float = 1.0,\n",
    "    big_m: float = 1e3\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds constraint expressions to a Pyomo model using Big-M logic. For each expression in expr_list,\n",
    "    the constraint is enforced only if the design variables lie in the corresponding critical region\n",
    "    defined in region_list.\n",
    "\n",
    "    Args:\n",
    "        expr_list: List of SymPy expressions representing SF constraints.\n",
    "        region_list: List of lists of SymPy inequality expressions defining valid regions.\n",
    "        instance: Pyomo model (ConcreteModel).\n",
    "        target: The minimum acceptable value for each SF expression.\n",
    "        big_m: Big-M constant for constraint activation.\n",
    "    \"\"\"\n",
    "    assert len(expr_list) == len(region_list), \"Each expression must have a corresponding region definition.\"\n",
    "\n",
    "    if not hasattr(instance, \"generated_constraints\"):\n",
    "        instance.generated_constraints = ConstraintList()\n",
    "    if not hasattr(instance, \"region_constraints\"):\n",
    "        instance.region_constraints = ConstraintList()\n",
    "    if not hasattr(instance, \"region_binaries\"):\n",
    "        instance.region_binaries = Var(range(len(expr_list)), within=Binary)\n",
    "\n",
    "    sf_expr_pyomo_list = list()\n",
    "\n",
    "    for i, (sf_expr, region_exprs) in enumerate(zip(expr_list, region_list)):\n",
    "        # Get all symbols in SF expression and region inequalities\n",
    "        all_syms = sf_expr.free_symbols.union(*[reg.free_symbols for reg in region_exprs])\n",
    "        all_syms = list(all_syms)\n",
    "\n",
    "        # Ensure all symbols are added to the Pyomo model\n",
    "        pyomo_vars = []\n",
    "        for sym in all_syms:\n",
    "            var_name = str(sym)\n",
    "            if not hasattr(instance, var_name):\n",
    "                setattr(instance, var_name, Var(bounds=bounds_dict[var_name]))\n",
    "            pyomo_vars.append(getattr(instance, var_name))\n",
    "\n",
    "        # Create a dict for substitution and lambdify\n",
    "        sym_to_pyomo = {str(sym): getattr(instance, str(sym)) for sym in all_syms}\n",
    "        lambdify_vars = list(sym_to_pyomo.keys())\n",
    "        lambdify_vals = [sym_to_pyomo[s] for s in lambdify_vars]\n",
    "\n",
    "        # Lambdify SF expression\n",
    "        sf_func = sp.lambdify(lambdify_vars, sf_expr, modules=[{'exp': pyo.exp, 'pi': math.pi}, 'sympy'])\n",
    "        sf_pyomo = sf_func(*lambdify_vals)\n",
    "        sf_expr_pyomo_list.append(sf_pyomo)\n",
    "\n",
    "        # Constraint: enforce SF ≥ target only when region binary = 1\n",
    "        instance.generated_constraints.add(\n",
    "            sf_pyomo >= target - big_m * (1 - instance.region_binaries[i])\n",
    "        )\n",
    "\n",
    "        # Region constraints: region_expr <= 0 + M*(1 - delta_i)\n",
    "        for reg_expr in region_exprs:\n",
    "            if not isinstance(reg_expr, sp.Rel):\n",
    "                raise ValueError(f\"Invalid region expression: {reg_expr} is not a relational (inequality) expression.\")\n",
    "\n",
    "            reg_func_lhs = sp.lambdify(lambdify_vars, reg_expr.lhs, modules='sympy')\n",
    "            reg_func_rhs = sp.lambdify(lambdify_vars, reg_expr.rhs, modules='sympy')\n",
    "            lhs_pyomo = reg_func_lhs(*lambdify_vals)\n",
    "            rhs_pyomo = reg_func_rhs(*lambdify_vals)\n",
    "\n",
    "            delta = instance.region_binaries[i]\n",
    "            M_term = big_m * (1 - delta)\n",
    "\n",
    "            if reg_expr.rel_op == '<=':\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo + M_term)\n",
    "            elif reg_expr.rel_op == '<':\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo - 1e-6 + M_term)\n",
    "            elif reg_expr.rel_op == '>=':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo - M_term)\n",
    "            elif reg_expr.rel_op == '>':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo + 1e-6 - M_term)\n",
    "            elif reg_expr.rel_op == '==':\n",
    "                instance.region_constraints.add(lhs_pyomo >= rhs_pyomo - M_term)\n",
    "                instance.region_constraints.add(lhs_pyomo <= rhs_pyomo + M_term)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported relational operator: {reg_expr.rel_op}\")\n",
    "\n",
    "    # Optional: Only one region can be active\n",
    "    instance.region_exclusivity = Constraint(expr=sum(instance.region_binaries[i] for i in range(len(expr_list))) == 1)\n",
    "    # if not hasattr(instance, 'sf'):\n",
    "    #     instance.sf = Var(within=NonNegativeReals)\n",
    "    # \n",
    "    # if not hasattr(instance, 'sf_con'):\n",
    "    #     instance.sf_con = Constraint(expr = instance.sf == sum(sf_expr_pyomo_list[i] * instance.region_binaries[i] for i in range(len(expr_list))))"
   ],
   "id": "5a46ed9ebf1f303f",
   "outputs": [],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "source": "t_bounds_list, t_regions_list = get_bounds_regions(sols=sol_list)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.744135Z",
     "start_time": "2025-07-11T13:42:18.729588Z"
    }
   },
   "id": "3952fe2d38a578e3",
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:18.760256Z",
     "start_time": "2025-07-11T13:42:18.745193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Define Symbols ---\n",
    "theta_syms = sp.symbols(f'theta_0:{nt}')\n",
    "d_syms = sp.symbols(f'd0:{nd}')\n",
    "theta_0, theta_1 = theta_syms\n",
    "d1, d2 = d_syms\n",
    "\n",
    "n_gl_list = [5,5]\n",
    "\n",
    "# # Bounds arrays\n",
    "# theta1_bounds_array = np.array([\n",
    "#     [[0.0, 0.0, 0.0], [0.0, 0.0, 4.0]],  # d0 ± 10\n",
    "#     [[0.75, -1.5, -1.25], [0.0, 0.0, 4.0]]  # d1 ± 5\n",
    "# ])\n",
    "# \n",
    "# theta2_bounds_array = np.array([\n",
    "#     [[-8/3, 2.0, -4.0, 2/3], [0.0, 0.0, 0.0, 4.0]],\n",
    "#     [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 4.0]],\n",
    "#     [[1/3, -0.5, 0.5, -1/3], [0.0, 0.0, 0.0, 4.0]]\n",
    "# ])\n",
    "# \n",
    "# # Critical regions (CRs)\n",
    "# # theta1_critical_regions: constraints in terms of d (shape: n_regions × n_ineqs × (m+1))\n",
    "# theta1_critical_regions = np.array([\n",
    "#     [[1, -2, -5/3]],\n",
    "#     [[-1, 2, 5/3]]\n",
    "# ], dtype=object)\n",
    "# \n",
    "# # theta2_critical_regions: constraints in terms of [theta1, d0, d1, const]\n",
    "# theta2_critical_regions = np.array([\n",
    "#     [[-8/3, 2, -4, -10/3], [8/3, -2, 4, -2/3]],\n",
    "#     [[8/3, -4.0, 4.0, -8/3], [-8/3, 2, -4, 2/3]],\n",
    "#     [[-8/3, 4, -4, 8/3]]\n",
    "# ], dtype=object)\n",
    "# \n",
    "# # --- Setup lists ---\n",
    "# theta_bounds_list = [theta1_bounds_array, theta2_bounds_array]\n",
    "# theta_regions_list = [theta1_critical_regions, theta2_critical_regions]\n",
    "\n",
    "joint_pdf_expr = (2/sp.pi) * sp.exp(-2 * ((theta_0 - 2) ** 2 + (theta_1 - 2) ** 2))"
   ],
   "id": "d625b5e86163b974",
   "outputs": [],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "source": [
    "sf_exprs, sf_regions = compute_sf_exprs_regions(theta_bounds_list=t_bounds_list, theta_regions_list=t_regions_list,\n",
    "                                                                              joint_pdf_expr=joint_pdf_expr, d_syms=[d1, d2], n_gl_list=n_gl_list,theta_syms=theta_syms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:35.250556Z",
     "start_time": "2025-07-11T13:42:18.777322Z"
    }
   },
   "id": "b34faf27411fcf53",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:35.266084Z",
     "start_time": "2025-07-11T13:42:35.252676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Number of SF expressions: {len(sf_exprs)}')\n",
    "print(f'Number of critical regions: {len(sf_regions)}')"
   ],
   "id": "d4d6ad3f0ee05b1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SF expressions: 486\n",
      "Number of critical regions: 486\n"
     ]
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:35.281233Z",
     "start_time": "2025-07-11T13:42:35.267222Z"
    }
   },
   "cell_type": "code",
   "source": "design_bounds = {f'd{i}':bounds for i, bounds in enumerate(d_bounds)}",
   "id": "f415a2d5a6f8076a",
   "outputs": [],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sf_target = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:20:35.076578Z",
     "start_time": "2025-07-11T14:20:35.067278Z"
    }
   },
   "id": "328a09c15871fc0e",
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m_sf = ConcreteModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:20:35.092106Z",
     "start_time": "2025-07-11T14:20:35.078666Z"
    }
   },
   "id": "5cd544206bdce086",
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generate_constraints_from_expressions(expr_list=sf_exprs, region_list=sf_regions, instance=m_sf, bounds_dict=design_bounds, target=sf_target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:20:58.729199Z",
     "start_time": "2025-07-11T14:20:35.105816Z"
    }
   },
   "id": "b0b9276af28b6ca",
   "execution_count": 245
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m_sf.obj = Objective(expr=-10*m_sf.d0 + 10*m_sf.d1, sense=minimize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:20:58.744609Z",
     "start_time": "2025-07-11T14:20:58.730351Z"
    }
   },
   "id": "c42df7339f8eb9b4",
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# m_sf.generated_constraints.pprint()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:20:58.759271Z",
     "start_time": "2025-07-11T14:20:58.745688Z"
    }
   },
   "id": "88aa4c1798ed4930",
   "execution_count": 247
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Job model.gms Start 07/11/25 09:20:59 45.7.0 64fbf3ce WEX-WEI x86 64bit/MS Windows\n",
      "--- Applying:\n",
      "    C:\\GAMS\\45\\gmsprmNT.txt\n",
      "--- GAMS Parameters defined\n",
      "    Input C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\model.gms\n",
      "    Output C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\output.lst\n",
      "    ScrDir C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\225a\\\n",
      "    SysDir C:\\GAMS\\45\\\n",
      "    CurDir C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\\n",
      "    LogOption 3\n",
      "Licensee: MUD - 30 User License                          G230830|0002AO-GEN\n",
      "          Texas A&M University, Chemical Engineering                DC11194\n",
      "          C:\\GAMS\\45\\gamslice.txt\n",
      "          License Admin: Jeff Polasek, j-polasek@tamu.edu                  \n",
      "          The maintenance period of the license expired on Jun 25, 2024\n",
      "          Please contact GAMS or your distributor for further information\n",
      "Processor information: 1 socket(s), 16 core(s), and 24 thread(s) available\n",
      "GAMS 45.7.0   Copyright (C) 1987-2024 GAMS Development. All rights reserved\n",
      "--- Starting compilation\n",
      "--- model.gms(32648) 12 Mb\n",
      "--- Starting execution: elapsed 0:00:00.075\n",
      "--- model.gms(21574) 13 Mb\n",
      "--- Generating MINLP model GAMS_MODEL\n",
      "--- model.gms(21575) 18 Mb\n",
      "--- Reset Solvelink = 2\n",
      "---   10,531 rows  489 columns  30,131 non-zeroes\n",
      "---   195,288 nl-code  970 nl-non-zeroes\n",
      "---   486 discrete-columns\n",
      "--- Range statistics (absolute non-zero finite values)\n",
      "--- RHS       [min, max] : [ 1.000E+00, 1.005E+03] - Zero values observed as well\n",
      "--- Bound     [min, max] : [ 1.000E+00, 5.000E+00] - Zero values observed as well\n",
      "--- Matrix    [min, max] : [ 6.384E-06, 1.000E+03]\n",
      "--- model.gms(21575) 15 Mb\n",
      "--- Executing BARON (Solvelink=2): elapsed 0:00:00.124\n",
      "\n",
      "GAMS/BARON       45.7.0 64fbf3ce Jan 18, 2024          WEI x86 64bit/MS Window\n",
      "===========================================================================\n",
      " BARON version 23.6.22. Built: WIN-64 Thu Jun 22 20:11:26 EDT 2023\n",
      "\n",
      " BARON is a product of The Optimization Firm.\n",
      " For information on BARON, see https://minlp.com/about-baron\n",
      "\n",
      " If you use this software, please cite publications from\n",
      " https://minlp.com/baron-publications, such as: \n",
      "\n",
      " Kilinc, M. and N. V. Sahinidis, Exploiting integrality in the global\n",
      " optimization of mixed-integer nonlinear programming problems in BARON,\n",
      " Optimization Methods and Software, 33, 540-562, 2018.\n",
      "===========================================================================\n",
      " This BARON run may utilize the following subsolver(s)\n",
      " For LP/MIP/QP: CLP/CBC, ILOG CPLEX                             \n",
      " For NLP: MINOS, SNOPT, External NLP, IPOPT, FILTERSQP\n",
      "===========================================================================\n",
      " Doing local search\n",
      " Solving bounding LP\n",
      " Starting multi-start local search\n",
      " Preprocessing found feasible solution with value -24.5843\n",
      " Done with local search\n",
      "===========================================================================\n",
      "  Iteration    Open nodes         Time (s)    Lower bound      Upper bound\n",
      "*         1             1             0.78     -48.8580         -37.2488       \n",
      "          1             0             1.89     -37.2525         -37.2488       \n",
      "\n",
      " Calculating duals\n",
      "\n",
      "                         *** Normal completion ***            \n",
      "\n",
      " Wall clock time:                     1.99\n",
      " Total CPU time used:                 1.92\n",
      "\n",
      " Total no. of BaR iterations:       1\n",
      " Best solution found at node:       1\n",
      " Max. no. of nodes in memory:       1\n",
      " \n",
      " All done\n",
      "===========================================================================\n",
      "\n",
      "Solution      = -37.2488028499677  found at node 1\n",
      "Best possible = -37.2525281028\n",
      "Absolute gap  = 0.00372525283231084  optca = 1E-9\n",
      "Relative gap  = 0.000100000000591392  optcr = 0.0001\n",
      "\n",
      "--- Reading solution for model GAMS_MODEL\n",
      "--- Executing after solve: elapsed 0:00:02.347\n",
      "--- model.gms(21578) 15 Mb\n",
      "--- model.gms(32648) 18 Mb\n",
      "--- Putfile results C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\results.dat\n",
      "--- Putfile statresults C:\\Users\\SHIVAM~1.VED\\AppData\\Local\\Temp\\tmpsmbo5f08\\resultsstat.dat\n",
      "*** Status: Normal completion\n",
      "--- Job model.gms Stop 07/11/25 09:21:01 elapsed 0:00:02.372\n"
     ]
    }
   ],
   "source": [
    "results = SolverFactory('gams', solver='baron').solve(m_sf, tee=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:01.986337Z",
     "start_time": "2025-07-11T14:20:58.760358Z"
    }
   },
   "id": "e055c00a7d99bf06",
   "execution_count": 248
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d0 : Size=1, Index=None\n",
      "    Key  : Lower : Value : Upper : Fixed : Stale : Domain\n",
      "    None :     0 :   5.0 :     5 : False : False :  Reals\n"
     ]
    }
   ],
   "source": [
    "m_sf.d0.pprint()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:02.002463Z",
     "start_time": "2025-07-11T14:21:01.987519Z"
    }
   },
   "id": "63b2c6cf81b2ebc",
   "execution_count": 249
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 : Size=1, Index=None\n",
      "    Key  : Lower : Value             : Upper : Fixed : Stale : Domain\n",
      "    None :     0 : 1.275119715003231 :     5 : False : False :  Reals\n"
     ]
    }
   ],
   "source": [
    "m_sf.d1.pprint()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:02.018155Z",
     "start_time": "2025-07-11T14:21:02.003516Z"
    }
   },
   "id": "ba6891abea46d6d3",
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Flexibility for the obtained design: 0.9000000000011382\n"
     ]
    }
   ],
   "source": [
    "active_idx = None\n",
    "for i in m_sf.region_binaries:\n",
    "    if pyo.value(m_sf.region_binaries[i]) > 0.9:\n",
    "        active_idx=i\n",
    "        break\n",
    "print(f'Stochastic Flexibility for the obtained design: {pyo.value(m_sf.generated_constraints[active_idx+1].body)+sf_target}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:02.033794Z",
     "start_time": "2025-07-11T14:21:02.019198Z"
    }
   },
   "id": "27e8d6ed30c13f95",
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-11T14:21:02.049427Z",
     "start_time": "2025-07-11T14:21:02.034842Z"
    }
   },
   "id": "7ab4c24ed8725561",
   "execution_count": 251
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
